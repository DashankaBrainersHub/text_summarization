{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Textsummary with t5 \n",
    "We will try out, how good the pretrained t5 model handels German text summarization. For this we will use the huggingface transfomer library and a dataset, which contains German wikipedia pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, TFT5Model, TFT5ForConditionalGeneration\n",
    "import tensorflow_datasets as tfds\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "SHUFFEL_SIZE = 1024\n",
    "\n",
    "learning_rate = 3e-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = TFT5ForConditionalGeneration.from_pretrained('t5-small')\n",
    "\n",
    "task_specific_params = model.config.task_specific_params\n",
    "if task_specific_params is not None:\n",
    "    model.config.update(task_specific_params.get(\"summarization\", {}))\n",
    "    \n",
    "pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_t5for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "shared (TFSharedEmbeddings)  multiple                  16449536  \n",
      "_________________________________________________________________\n",
      "encoder (TFT5MainLayer)      multiple                  18881280  \n",
      "_________________________________________________________________\n",
      "decoder (TFT5MainLayer)      multiple                  25176064  \n",
      "=================================================================\n",
      "Total params: 60,506,880\n",
      "Trainable params: 60,506,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08, clipnorm=1.0)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We will try out a german Dataset which is an extract from the german Wikipedia Page. The first section is used for the summaray which should be predicted by the rest of the article. \n",
    "### References:\n",
    "- Fecht, Pascal, Sebastian Blank, and Hans-Peter Zorn. \"Sequential Transfer Learning in NLP for German Text Summarization.\" (2019).\n",
    "- https://drive.switch.ch/index.php/s/YoyW9S8yml7wVhN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/german/swisstext/data_train.csv\")\n",
    "len_data = len(data)\n",
    "len_test = int(len_data * 0.1)\n",
    "len_train = len_data - len_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data.iloc[:len_test]\n",
    "train_data = data.iloc[len_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Minghella war der Sohn italienisch-schottische...</td>\n",
       "      <td>Anthony Minghella, CBE war ein britischer Film...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ende der 1940er Jahre wurde eine erste Auteur-...</td>\n",
       "      <td>Die Auteur-Theorie ist eine Filmtheorie und di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al Pacino, geboren in Manhattan, ist der Sohn ...</td>\n",
       "      <td>Alfredo James \"Al\" Pacino ist ein US-amerikani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Der Name der Alkalimetalle leitet sich von dem...</td>\n",
       "      <td>Als Alkalimetalle werden die chemischen Elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Die Arbeit ist bereits seit dem Altertum Gegen...</td>\n",
       "      <td>Das deutsche Arbeitsrecht ist ein Rechtsgebiet...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              source  \\\n",
       "0  Minghella war der Sohn italienisch-schottische...   \n",
       "1  Ende der 1940er Jahre wurde eine erste Auteur-...   \n",
       "2  Al Pacino, geboren in Manhattan, ist der Sohn ...   \n",
       "3  Der Name der Alkalimetalle leitet sich von dem...   \n",
       "4  Die Arbeit ist bereits seit dem Altertum Gegen...   \n",
       "\n",
       "                                             summary  \n",
       "0  Anthony Minghella, CBE war ein britischer Film...  \n",
       "1  Die Auteur-Theorie ist eine Filmtheorie und di...  \n",
       "2  Alfredo James \"Al\" Pacino ist ein US-amerikani...  \n",
       "3  Als Alkalimetalle werden die chemischen Elemen...  \n",
       "4  Das deutsche Arbeitsrecht ist ein Rechtsgebiet...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfds = tf.data.Dataset.from_tensor_slices((train_data.source.values, train_data.summary.values))\n",
    "test_tfds = tf.data.Dataset.from_tensor_slices((test_data.source.values, test_data.summary.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    \"\"\"Lowercase and remove quotes from a TensorFlow string.\"\"\"\n",
    "    text = tf.strings.lower(text)\n",
    "    text = tf.strings.regex_replace(text,\"'(.*)'\", r\"\\1\")\n",
    "    return text.numpy().decode('UTF-8')\n",
    "\n",
    "def tokenize_articles(text):\n",
    "    text = normalize_text(text)\n",
    "    ids = tokenizer.encode_plus((model.config.prefix + text), return_tensors=\"tf\", max_length=512) \n",
    "\n",
    "    return tf.squeeze(ids['input_ids']), tf.squeeze(ids['attention_mask'])\n",
    "        \n",
    "def tokenize_highlights(text):\n",
    "    text = normalize_text(text)\n",
    "    ids = tokenizer.encode(text, return_tensors=\"tf\", max_length=150)\n",
    "    return tf.squeeze(ids)\n",
    "\n",
    "\n",
    "def map_func(x, y):\n",
    "    article_ids, attention_mask = tf.py_function(tokenize_articles, inp=[x], Tout=(tf.int32, tf.int32))\n",
    "    highlights_ids = tf.py_function(tokenize_highlights, inp=[y], Tout=tf.int32)\n",
    "\n",
    "    return article_ids, attention_mask, highlights_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([512]), TensorShape([512]), TensorShape([78]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(train_tfds))\n",
    "\n",
    "mapped_data = map_func(x,y)\n",
    "\n",
    "mapped_data[0].shape, mapped_data[1].shape, mapped_data[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_tfds.map(map_func)\\\n",
    "    .shuffle(SHUFFEL_SIZE)\\\n",
    "    .padded_batch(BATCH_SIZE, padded_shapes=([512],[512],[150]))\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_ds = test_tfds.map(map_func)\\\n",
    "    .shuffle(SHUFFEL_SIZE)\\\n",
    "    .padded_batch(BATCH_SIZE, padded_shapes=([512],[512],[150]))\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train and Validation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_ids, input_mask, y):\n",
    "    # https://github.com/huggingface/transformers/blob/master/examples/summarization/bart/finetune.py\n",
    "    y_ids = y[:, :-1]\n",
    "    lm_labels = tf.identity(y[:, 1:])\n",
    "    lm_labels = tf.where(tf.equal(y[:, 1:],pad_token_id), -100, lm_labels)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # prediction_scores: (bs, 150, 32128)\n",
    "        # decoder_past_key_value_states: (bs, 512, 512), (bs, 8, 150, 64)\n",
    "        # z: (bs, 512, 512)\n",
    "        predictions, _, _ = model(input_ids, attention_mask=input_mask, decoder_input_ids=y_ids, lm_labels=lm_labels, training=True)\n",
    "        loss = loss_object(y[:, 1:], predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(y[:, 1:], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(input_ids, input_mask, y):\n",
    "    # https://github.com/huggingface/transformers/blob/master/examples/summarization/bart/finetune.py\n",
    "    y_ids = y[:, :-1]\n",
    "    lm_labels = tf.identity(y[:, 1:])\n",
    "    lm_labels = tf.where(tf.equal(y[:, 1:],pad_token_id), -100, lm_labels)\n",
    "    \n",
    "    predictions, _, _ = model(input_ids, attention_mask=input_mask, decoder_input_ids=y_ids, lm_labels=lm_labels, training=False)\n",
    "    v_loss = loss_object(y[:, 1:], predictions)\n",
    "\n",
    "    val_loss(v_loss)\n",
    "    val_accuracy(y[:, 1:], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yannik/Dokumente/text_summarization/venv/lib/python3.8/site-packages/tensorflow/python/framework/indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | [    0/ 5625] | ms/batch 115.10 | train acc 12.96 | val acc 14.60 |loss  9.27 | val loss  9.25\n",
      "| epoch   0 | [  200/ 5625] | ms/batch 316.69 | train acc 58.47 | val acc 45.45 |loss  2.60 | val loss  5.27\n",
      "| epoch   0 | [  400/ 5625] | ms/batch 319.34 | train acc 63.64 | val acc 55.68 |loss  2.19 | val loss  3.95\n",
      "| epoch   0 | [  600/ 5625] | ms/batch 326.31 | train acc 66.10 | val acc 60.26 |loss  2.00 | val loss  3.31\n",
      "| epoch   0 | [  800/ 5625] | ms/batch 329.76 | train acc 67.58 | val acc 63.08 |loss  1.89 | val loss  2.92\n",
      "| epoch   0 | [ 1000/ 5625] | ms/batch 328.81 | train acc 68.59 | val acc 64.39 |loss  1.82 | val loss  2.70\n",
      "| epoch   0 | [ 1200/ 5625] | ms/batch 330.43 | train acc 69.41 | val acc 65.51 |loss  1.76 | val loss  2.53\n",
      "| epoch   0 | [ 1400/ 5625] | ms/batch 332.65 | train acc 70.07 | val acc 66.66 |loss  1.71 | val loss  2.38\n",
      "| epoch   0 | [ 1600/ 5625] | ms/batch 326.68 | train acc 70.67 | val acc 67.80 |loss  1.67 | val loss  2.25\n",
      "| epoch   0 | [ 1800/ 5625] | ms/batch 324.65 | train acc 71.18 | val acc 69.02 |loss  1.63 | val loss  2.12\n",
      "| epoch   0 | [ 2000/ 5625] | ms/batch 324.03 | train acc 71.69 | val acc 69.12 |loss  1.60 | val loss  2.08\n",
      "| epoch   0 | [ 2200/ 5625] | ms/batch 323.92 | train acc 72.12 | val acc 69.30 |loss  1.57 | val loss  2.03\n",
      "| epoch   0 | [ 2400/ 5625] | ms/batch 324.26 | train acc 72.49 | val acc 69.55 |loss  1.54 | val loss  1.99\n",
      "| epoch   0 | [ 2600/ 5625] | ms/batch 324.15 | train acc 72.81 | val acc 69.84 |loss  1.52 | val loss  1.95\n",
      "| epoch   0 | [ 2800/ 5625] | ms/batch 324.17 | train acc 73.14 | val acc 70.49 |loss  1.50 | val loss  1.89\n",
      "| epoch   0 | [ 3000/ 5625] | ms/batch 328.36 | train acc 73.41 | val acc 70.89 |loss  1.48 | val loss  1.85\n",
      "| epoch   0 | [ 3200/ 5625] | ms/batch 332.54 | train acc 73.72 | val acc 71.00 |loss  1.46 | val loss  1.82\n",
      "| epoch   0 | [ 3400/ 5625] | ms/batch 332.54 | train acc 73.99 | val acc 70.82 |loss  1.44 | val loss  1.81\n",
      "| epoch   0 | [ 3600/ 5625] | ms/batch 329.98 | train acc 74.19 | val acc 71.09 |loss  1.43 | val loss  1.79\n",
      "| epoch   0 | [ 3800/ 5625] | ms/batch 326.54 | train acc 74.37 | val acc 71.37 |loss  1.42 | val loss  1.76\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "log_interval = 200\n",
    "for epoch in range(EPOCHS):\n",
    "    # reset metrics\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    val_loss.reset_states()\n",
    "    val_accuracy.reset_states()\n",
    "    \n",
    "    val_batches = iter(train_ds)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i, (input_ids, input_mask, y) in enumerate(train_ds):\n",
    "        # training\n",
    "        train_step(input_ids, input_mask, y)\n",
    "        \n",
    "        # validation\n",
    "        if i % log_interval == 0:\n",
    "            x_val, x_mask_val, y_val = next(val_batches)\n",
    "            val_step(x_val, x_mask_val, y_val)\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | [{:5d}/{:5d}] | '\n",
    "                  'ms/batch {:5.2f} | '\n",
    "                  'train acc {:5.2f} | val acc {:5.2f} |'\n",
    "                  'loss {:5.2f} | val loss {:5.2f}'.format(\n",
    "                    epoch, i, int(len_train/BATCH_SIZE),\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    train_accuracy.result() * 100, val_accuracy.result() * 100, \n",
    "                    train_loss.result(),  val_loss.result()))\n",
    "            start_time = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### Define Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from rouge_score import scoring\n",
    "\n",
    "class RougeScore:\n",
    "    '''\n",
    "    mostly from https://github.com/google-research/text-to-text-transfer-transformer/blob/master/t5/evaluation/metrics.py \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, score_keys=None)-> None:\n",
    "        super().__init__()\n",
    "        if score_keys is None:  \n",
    "            self.score_keys = [\"rouge1\", \"rouge2\", \"rougeLsum\"]\n",
    "        \n",
    "        self.scorer = rouge_scorer.RougeScorer(self.score_keys)\n",
    "        self.aggregator = scoring.BootstrapAggregator()\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def prepare_summary(summary):\n",
    "            # Make sure the summary is not bytes-type\n",
    "            # Add newlines between sentences so that rougeLsum is computed correctly.\n",
    "            summary = summary.replace(\" . \", \" .\\n\")\n",
    "            return summary\n",
    "    \n",
    "    def __call__(self, target, prediction):\n",
    "        \"\"\"Computes rouge score.''\n",
    "        Args:\n",
    "        targets: string\n",
    "        predictions: string\n",
    "        \"\"\"\n",
    "\n",
    "        target = self.prepare_summary(target)\n",
    "        prediction = self.prepare_summary(prediction)\n",
    "        \n",
    "        self.aggregator.add_scores(self.scorer.score(target=target, prediction=prediction))\n",
    "\n",
    "        return \n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.rouge_list = []\n",
    "\n",
    "    def result(self):\n",
    "        result = self.aggregator.aggregate()\n",
    "        \n",
    "        for key in self.score_keys:\n",
    "            score_text = \"%s = %.2f, 95%% confidence [%.2f, %.2f]\"%(\n",
    "                key,\n",
    "                result[key].mid.fmeasure*100,\n",
    "                result[key].low.fmeasure*100,\n",
    "                result[key].high.fmeasure*100\n",
    "            )\n",
    "            print(score_text)\n",
    "        \n",
    "        return {key: result[key].mid.fmeasure*100 for key in self.score_keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "rouge_score = RougeScore()\n",
    "for i, (input_ids, input_mask, y) in enumerate(test_ds):\n",
    "    summaries = model.generate(input_ids=input_ids, attention_mask=input_mask)\n",
    "\n",
    "    pred = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summaries]\n",
    "    real = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in y]\n",
    "    \n",
    "    for pred_sent, real_sent in zip(pred, real):\n",
    "        rouge_score(pred_sent, real_sent)\n",
    "        predictions.append(str(\"pred sentence: \" + pred_sent + \"\\n\\n real sentence: \" + real_sent))\n",
    "        \n",
    "    if i > 10:\n",
    "        # otherwise it will take ages\n",
    "        break\n",
    "\n",
    "\n",
    "rouge_score.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict some Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pred in predictions[:10]:\n",
    "    print(\"------\")\n",
    "    print(pred)\n",
    "    print(\"------\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textsummary",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
