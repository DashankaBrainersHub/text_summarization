{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Textsummary with t5 \n",
    "We will try out, how good the pretrained t5 model handels German text summarization. For this we will use the huggingface transfomer library and a dataset, which contains German wikipedia pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, TFT5Model, TFT5ForConditionalGeneration\n",
    "import tensorflow_datasets as tfds\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "\n",
    "SHUFFEL_SIZE = 1024\n",
    "\n",
    "learning_rate = 3e-5\n",
    "\n",
    "model_size = \"t5-base\"\n",
    "\n",
    "MAX_ARTICLE_LEN = 512\n",
    "\n",
    "MAX_HIGHLIGHT_LEN = 150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(model_size)\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(model_size)\n",
    "\n",
    "task_specific_params = model.config.task_specific_params\n",
    "if task_specific_params is not None:\n",
    "    model.config.update(task_specific_params.get(\"summarization\", {}))\n",
    "    \n",
    "pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_t5for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "shared (TFSharedEmbeddings)  multiple                  24674304  \n",
      "_________________________________________________________________\n",
      "encoder (TFT5MainLayer)      multiple                  84954240  \n",
      "_________________________________________________________________\n",
      "decoder (TFT5MainLayer)      multiple                  113275392 \n",
      "=================================================================\n",
      "Total params: 222,903,936\n",
      "Trainable params: 222,903,936\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08, clipnorm=1.0)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fe29c3875b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_file = \"../models/ckpt/checkpoint.ckpt\"\n",
    "model.load_weights(ckpt_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "We will try out a german Dataset which is an extract from the german Wikipedia Page. The first section is used for the summaray which should be predicted by the rest of the article. \n",
    "### References:\n",
    "- Fecht, Pascal, Sebastian Blank, and Hans-Peter Zorn. \"Sequential Transfer Learning in NLP for German Text Summarization.\" (2019).\n",
    "- https://drive.switch.ch/index.php/s/YoyW9S8yml7wVhN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data\"\n",
    "\n",
    "def get_tfrecord_dataset(drive_path, file_name):\n",
    "    features = {\n",
    "        'x': tf.io.FixedLenFeature([MAX_ARTICLE_LEN], tf.int64),\n",
    "        'x_mask': tf.io.FixedLenFeature([MAX_ARTICLE_LEN], tf.int64),\n",
    "        'y': tf.io.FixedLenFeature([MAX_HIGHLIGHT_LEN], tf.int64),\n",
    "        'y_ids': tf.io.FixedLenFeature([MAX_HIGHLIGHT_LEN - 1], tf.int64),\n",
    "        'y_labels': tf.io.FixedLenFeature([MAX_HIGHLIGHT_LEN - 1], tf.int64),\n",
    "    }\n",
    "\n",
    "    dataset = tf.data.TFRecordDataset(f\"{drive_path}/{file_name}.tfrecord\")\n",
    "\n",
    "    # Taken from the TensorFlow models repository: https://github.com/tensorflow/models/blob/befbe0f9fe02d6bc1efb1c462689d069dae23af1/official/nlp/bert/input_pipeline.py#L24\n",
    "    def decode_record(record, features):\n",
    "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
    "        example = tf.io.parse_single_example(record, features)\n",
    "\n",
    "        # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
    "        # So cast all int64 to int32.\n",
    "        for name in list(example.keys()):\n",
    "            t = example[name]\n",
    "            if t.dtype == tf.int64:\n",
    "                t = tf.cast(t, tf.int32)\n",
    "            example[name] = t\n",
    "        return example\n",
    "\n",
    "\n",
    "    def select_data_from_record(record):\n",
    "        return record['x'], record['x_mask'], record['y'], record['y_ids'], record['y_labels']\n",
    "\n",
    "\n",
    "    dataset = dataset.map(lambda record: decode_record(record, features))\n",
    "    dataset = dataset.map(select_data_from_record)\n",
    "    dataset = dataset.shuffle(100)\n",
    "    return dataset.batch(BATCH_SIZE)\n",
    "\n",
    "train_ds = get_tfrecord_dataset(path, \"train_cnn_daily_mail\")\n",
    "train_ds.prefetch(1024)\n",
    "\n",
    "val_ds = get_tfrecord_dataset(path, \"val_cnn_daily_mail\")\n",
    "test_ds = get_tfrecord_dataset(path, \"test_cnn_daily_mail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Train and Validation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_ids, input_mask, y):\n",
    "    # https://github.com/huggingface/transformers/blob/master/examples/summarization/bart/finetune.py\n",
    "    y_ids = y[:, :-1]\n",
    "    lm_labels = tf.identity(y[:, 1:])\n",
    "    lm_labels = tf.where(tf.equal(y[:, 1:],pad_token_id), -100, lm_labels)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # prediction_scores: (bs, 150, 32128)\n",
    "        # decoder_past_key_value_states: (bs, 512, 512), (bs, 8, 150, 64)\n",
    "        # z: (bs, 512, 512)\n",
    "        predictions, _, _ = model(input_ids, attention_mask=input_mask, decoder_input_ids=y_ids, lm_labels=lm_labels, training=True)\n",
    "        loss = loss_object(y[:, 1:], predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(y[:, 1:], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(input_ids, input_mask, y):\n",
    "    # https://github.com/huggingface/transformers/blob/master/examples/summarization/bart/finetune.py\n",
    "    y_ids = y[:, :-1]\n",
    "    lm_labels = tf.identity(y[:, 1:])\n",
    "    lm_labels = tf.where(tf.equal(y[:, 1:],pad_token_id), -100, lm_labels)\n",
    "    \n",
    "    predictions, _, _ = model(input_ids, attention_mask=input_mask, decoder_input_ids=y_ids, lm_labels=lm_labels, training=False)\n",
    "    v_loss = loss_object(y[:, 1:], predictions)\n",
    "\n",
    "    val_loss(v_loss)\n",
    "    val_accuracy(y[:, 1:], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-8074290c5563>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "log_interval = 200\n",
    "for epoch in range(EPOCHS):\n",
    "    # reset metrics\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    val_loss.reset_states()\n",
    "    val_accuracy.reset_states()\n",
    "    \n",
    "    val_batches = iter(train_ds)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i, (input_ids, input_mask, y) in enumerate(train_ds):\n",
    "        # training\n",
    "        train_step(input_ids, input_mask, y)\n",
    "        \n",
    "        # validation\n",
    "        if i % log_interval == 0:\n",
    "            x_val, x_mask_val, y_val = next(val_batches)\n",
    "            val_step(x_val, x_mask_val, y_val)\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | [{:5d}/{:5d}] | '\n",
    "                  'ms/batch {:5.2f} | '\n",
    "                  'train acc {:5.2f} | val acc {:5.2f} |'\n",
    "                  'loss {:5.2f} | val loss {:5.2f}'.format(\n",
    "                    epoch, i, int(len_train/BATCH_SIZE),\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    train_accuracy.result() * 100, val_accuracy.result() * 100, \n",
    "                    train_loss.result(),  val_loss.result()))\n",
    "            start_time = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### Define Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from rouge_score import scoring\n",
    "\n",
    "class RougeScore:\n",
    "    '''\n",
    "    mostly from https://github.com/google-research/text-to-text-transfer-transformer/blob/master/t5/evaluation/metrics.py \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, score_keys=None)-> None:\n",
    "        super().__init__()\n",
    "        if score_keys is None:  \n",
    "            self.score_keys = [\"rouge1\", \"rouge2\", \"rougeLsum\"]\n",
    "        \n",
    "        self.scorer = rouge_scorer.RougeScorer(self.score_keys)\n",
    "        self.aggregator = scoring.BootstrapAggregator()\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def prepare_summary(summary):\n",
    "            # Make sure the summary is not bytes-type\n",
    "            # Add newlines between sentences so that rougeLsum is computed correctly.\n",
    "            summary = summary.replace(\" . \", \" .\\n\")\n",
    "            return summary\n",
    "    \n",
    "    def __call__(self, target, prediction):\n",
    "        \"\"\"Computes rouge score.''\n",
    "        Args:\n",
    "        targets: string\n",
    "        predictions: string\n",
    "        \"\"\"\n",
    "\n",
    "        target = self.prepare_summary(target)\n",
    "        prediction = self.prepare_summary(prediction)\n",
    "        \n",
    "        self.aggregator.add_scores(self.scorer.score(target=target, prediction=prediction))\n",
    "\n",
    "        return \n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.rouge_list = []\n",
    "\n",
    "    def result(self):\n",
    "        result = self.aggregator.aggregate()\n",
    "        \n",
    "        for key in self.score_keys:\n",
    "            score_text = \"%s = %.2f, 95%% confidence [%.2f, %.2f]\"%(\n",
    "                key,\n",
    "                result[key].mid.fmeasure*100,\n",
    "                result[key].low.fmeasure*100,\n",
    "                result[key].high.fmeasure*100\n",
    "            )\n",
    "            print(score_text)\n",
    "        \n",
    "        return {key: result[key].mid.fmeasure*100 for key in self.score_keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : time genreate batch: 4.1929614543914795\n",
      "10 : time genreate batch: 41.376852941513064\n",
      "20 : time genreate batch: 40.70076382160187\n",
      "30 : time genreate batch: 40.81612327098846\n",
      "40 : time genreate batch: 41.42829957008362\n",
      "50 : time genreate batch: 41.02130627632141\n",
      "rouge1 = 31.99, 95% confidence [31.11, 32.82]\n",
      "rouge2 = 13.15, 95% confidence [12.33, 13.98]\n",
      "rougeLsum = 20.85, 95% confidence [20.06, 21.69]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 31.98689458447781,\n",
       " 'rouge2': 13.145598563447209,\n",
       " 'rougeLsum': 20.85349735088455}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "rouge_score = RougeScore()\n",
    "start_time = time.time()\n",
    "\n",
    "for i, (input_ids, input_mask, y, y_ids, y_labels) in enumerate(test_ds):   \n",
    "    summaries = model.generate(input_ids=input_ids, attention_mask=input_mask, max_length=150, early_stopping=True)\n",
    "\n",
    "    pred = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summaries]\n",
    "    real = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in y]\n",
    "    \n",
    "    for pred_sent, real_sent in zip(pred, real):\n",
    "        rouge_score(pred_sent, real_sent)\n",
    "        predictions.append(str(\"pred sentence: \" + pred_sent + \"\\n\\nreal sentence: \" + real_sent))\n",
    "    \n",
    "    if (i % 10) == 0:\n",
    "        elapsed = (time.time() - start_time) / 10\n",
    "        print(i,\": time genreate batch:\", elapsed)\n",
    "        start_time = time.time()\n",
    "    if i > 51:\n",
    "        # otherwise it will take ages\n",
    "        break\n",
    "\n",
    "\n",
    "rouge_score.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict some Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "pred sentence: dorinta Napoli-Boss Rafael Benitez steht vor dem entscheidenden Serie-A-Spiel gegen Sampdoria an diesem Wochenende erneut in der Kritik. Der Spanier wird mit dem Managerjob in Verbindung gebracht, nachdem bekannt wurde, dass Sinisa Mihajlovic - der aktuelle Blucerchiati-Chef - als Nachfolger von Bentez im Gespräch ist. Samporia-Präsident Massimo Ferrero hat sich von einem Lieblingsgesang des Goodison Parks und der Terrassen von Old Trafford inspirieren lassen und scheint Gerüchte über einen bevorstehenden Jobwechsel zu zerstreuen\n",
      "\n",
      "real sentence: Der Ex-Liverpool-Boss sagte, dass er vor der Ernennung einen Ernährungsberater aufsuchen müsse. Benitez wurde während seiner Zeit in Anfield oft als \"fetter spanischer Kellner\" verspottet. Ferrero spricht von einem Jobwechsel mit Sinisa Mihajlovic, der Sampdoria an den Rand der europäischen Qualifikation geführt hat.\n",
      "------\n",
      "------\n",
      "pred sentence: dorinten, nach zwei Niederlagen in Folge in Craven Cottage einen Punkt zu ergattern. Gary Caldwell gab zu, dass sein erster Vorgeschmack auf das Management \"verrückt\" war. Die Latics steuern zwar auf den Abstieg zu, aber sie haben gezeigt, dass sie bereit sind, einen Punkt in der Meisterschaft zu holen. Caledwell ersetzte erst am Mittwoch den angeschlagenen Malky Mackay. Der ehemalige Latics-Kapitän sagte, er habe den Spielern gerade gesagt, dass er sehr stolz auf sie bin, wenn man bedenkt, dass wir nur zwei Tage Zeit hatten, um zu\n",
      "\n",
      "real sentence: Fulham 2-2 Wigan Athletic: HIER KLICKEN, um den Spielbericht zu lesen. Latics kam zweimal von hinten, um die Cottagers zu betäuben. Gary Caldwell gab zu, dass sein erster Vorgeschmack auf das Management \"verrückt\" war.\n",
      "------\n",
      "------\n",
      "pred sentence: <extra_id_0> Bruce Jenner, 65, wird am Freitag, 24. April, in einem \"weitreichenden\" Interview mit Sawyer für eine Sonderausgabe von \"20 / 20\" sprechen. Das Interview findet inmitten wachsender Spekulationen über den Übergang des sechsfachen Vaters zu einer Frau statt und steht unmittelbar hinter seiner Verwicklung in einen tödlichen Autounfall in Kalifornien im Februar. Jenners Geschlechtsidentität begann im letzten Jahr, als er aus einer Klinik in Beverly Hills mit abrasiertem Adam 's Apfel auftauchte. Er trennte sich von seiner mehr als zwei Jahrzehnte alten\n",
      "\n",
      "real sentence: Das Interview mit dem Reality-TV-Star, 69, wird am Freitag, den 24. April ausgestrahlt, inmitten anhaltender Spekulationen über seinen Wechsel zu einer Frau und nach seiner Verwicklung in einen tödlichen Autounfall im Februar. Das Interview wird auch einer von Diane Sawyers ersten Fernsehauftritten nach dem plötzlichen Tod ihres Mannes im vergangenen Jahr sein.\n",
      "------\n",
      "------\n",
      "pred sentence: <extra_id_0> Boca Juniors besiegte Palestino in der Copa Libertadores mit 2: 0. Leandro Marin brachte die argentinischen Giganten mit einem Kopfballtor in der Schlussminute in Führung. Jonatan Calleri erzielte in der zweiten Halbzeit alle drei Punkte. River Plate hielt am Mittwoch mit einem 3: 0-Sieg in Zamora den zweiten Platz in der Gruppe A. Boca-Boss Rodolfo Arruabarrena sagte: \"Es wird hart und anstrengend. Wir haben Vertrauen in unsere Mannschaft und werden versuchen, alles richtig zu machen,\n",
      "\n",
      "real sentence: Boca Juniors besiegte Palestino mit 2: 0 durch zwei späte Tore in der zweiten Halbzeit. Leandro Marin und Jonatan Calleri trugen sich beide in die Torschützenliste ein. Boca trifft nun im Achtelfinale der Copa Libertadores auf Erzrivale River Plate.\n",
      "------\n",
      "------\n",
      "pred sentence: <extra_id_0> Ermias Ghermay soll mit seinem Komplizen Mered Medhanie in den letzten zwei Jahren 72 Millionen Pfund durch Schmuggel verdient haben. Einer von ihnen, ein Eritreer, hörte auf einem Polizeiabhörgerät über die Überladung von Migrantenschiffen lachen, ein Problem, das sie zum Kentern bringt. Ein zweiter Menschenhändler, der in Tripolis lebt, wurde bereits im Zusammenhang mit einem Kentern vor Lampedusa im Oktober 2013 mit 366 Toten per Haftbefehl gesucht. Ghermails Foto wurde gestern veröffentlicht, als sie das Paar aufspüren wollten.\n",
      "\n",
      "real sentence: Mered Medhanie und Ermias Ghermay \"haben in den letzten zwei Jahren £72 Millionen verdient\" Medhanie hörte auf Polizeiabhörgeräten Spott über die fatale Überbelegung von Schiffen. Ghermay soll gesagt haben: \"Ich weiß nicht, was passiert ist, sie sind wahrscheinlich gestorben\". Pair wollte über einen großen Schmugglerring, versteckt sich aber im gesetzlosen Libyen.\n",
      "------\n",
      "------\n",
      "pred sentence: dorintscher Flügelspieler Tom Lineham erzielte zwei Abfangversuche, als Hull FC Widnes besiegte. Der Hattrick macht ihn 2015 zum erfolgreichsten Spieler der Super League. Jamie Shaul sorgte spät für die beiden Punkte für Hull. Kevin Brown und Patrick Ah Van Widdes schafften es nicht, die Auswärtsniederlage zu erzwingen. Hull gewann am Freitagabend zum ersten Mal seit Juni letzten Jahres wieder zum Sieg. Der 22-Jährige erzielte im letzten Monat in Castleford ein Triple in einer Verlierersache, aber seine Bemühungen beendeten einen trostlosen Wett\n",
      "\n",
      "real sentence: Tom Lineham erzielte zwei Abfangversuche in einem auffälligen Schaulaufen. Jamie Shaul traf ebenfalls spät für die Heimmannschaft. Kevin Brown und Patrick Ah Van antworteten für Widnes.\n",
      "------\n",
      "------\n",
      "pred sentence: frunzetete Kind raste zurück in Sicherheit, nachdem es eine Reihe von Raketen auf sechs schwer bewaffnete Offiziere abgefeuert hatte. Der Vorfall ereignete sich während der jährlichen Demonstrationen anlässlich des Tages der palästinensischen Gefangenen im nördlichen Westjordanland. Die israelische Polizei setzte Tränengas und Gummigeschosse ein, um die Menge auseinanderzutreiben, als die Gewalt auf den Straßen aufflackerte. Die Polizei befürchtete, dass Kinder ermutigt werden könnten, Gewalt nachzua\n",
      "\n",
      "real sentence: Der fünfjährige Junge bewirft die Polizei mit Steinen, als palästinensische Demonstranten im nördlichen Westjordanland mit der israelischen Polizei zusammenstoßen. Die Gewalt brach aus, nachdem mehr als 100 Demonstranten an einer Kundgebung anlässlich des Tages der palästinensischen Gefangenen teilgenommen hatten. Israel hat seit 1967 rund 800.000 Palästinenser in den besetzten Gebieten festgenommen, von denen derzeit 6.000 festgehalten werden.\n",
      "------\n",
      "------\n",
      "pred sentence: dorinten, den Titel und den FA Cup zu gewinnen, das ist es, was ich will \". Der rechte Verteidiger des FC Southampton wurde in dieser Saison viermal von England verpflichtet. Ronald Koeman räumte kürzlich ein, dass der Klub vor einem Kampf stehe, um den ehemaligen Crystal Palace-Mittelfeldakteur zu halten. Clyne nahm am Sonntagabend an einer Benefizveranstaltung für die Football Fighting Ebola Kampagne teil, die am Sonntag Abend in Old Trafford stattfand. Der ehemalige Southampton-Boss hat zugegeben, dass er in diesem Sommer beim Klub\n",
      "\n",
      "real sentence: Nathaniel Clyne war in dieser Saison in beeindruckender Form für Southampton. Voller Einsatz wurde mit einem Wechsel zu Manchester United in diesem Sommer in Verbindung gebracht. Clyne gibt zu, dass er ehrgeizig ist und in der Champions League spielen will.\n",
      "------\n",
      "------\n",
      "pred sentence: <extra_id_0> Mohammed Ali Malek, 27, wurde verhaftet, als er sizilianischen Boden betrat, etwa 24 Stunden nachdem sein Boot im Mittelmeer gekentert war. Bevor er jedoch das Schiff der italienischen Küstenwache verließ, musste er mit ansehen, wie die Leichen von 24 Opfern der Tragödie von Bord getragen wurden. Später wurde er wegen mehrfachen Totschlags, Herbeiführens eines Schiffbruchs und Beihilfe zur illegalen Einwanderung angeklagt. Die Staatsanwaltschaft behauptet, er habe zu der Katastrophe\n",
      "\n",
      "real sentence: Mohammed Ali Malek, 27, wurde wegen mehrfachen Totschlags angeklagt. Ankunft in Malta auf einem italienischen Rettungsschiff mit den Leichen von 24 Migrantenopfern. Er wurde zusammen mit seinem 26-jährigen syrischen \"Schlepper-Komplizen\" festgenommen. Laut Staatsanwaltschaft stürzte Malek auf das Schiff, das ihm zu Hilfe gekommen war. Migranten wechselten dann infolge der Kollision ihre Position und brachten es zum Kentern.\n",
      "------\n",
      "------\n",
      "pred sentence: tories und labour sehen sich knapp vor David Cameron und Ed Miliband. Experten warnen vor den Auswirkungen eines schlecht regierten Parlaments auf die Wirtschaft. Es gibt Befürchtungen, dass das Pfund um weitere 10 Prozent abstürzen könnte. Das Pfund fiel gegenüber dem US-Dollar auf fast 1,46 Dollar, kurz nach der letzten Wahl, als keine Partei eine Mehrheit erreichte. Das Industriewachstum im Februar ist nur um 0,1 Prozent gewachsen, das Baugewerbe schrumpfte um 0,9 Prozent nach einem Rückgang um 2,5 Prozent im Januar. Industrieproduktion stieg im Februar um 0,1%.\n",
      "\n",
      "real sentence: Pfund in der Nähe von 1,46 gegenüber dem US-Dollar, dem niedrigsten Stand seit Juni 2010. Umfragen deuten darauf hin, dass es weder Tories noch Labour schaffen werden, eine Mehrheit zu erringen.\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for pred in predictions[:10]:\n",
    "    print(\"------\")\n",
    "    print(pred)\n",
    "    print(\"------\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = \"../data/t5base_result_german.txt\"\n",
    "open(result_path, \"w\")\n",
    "for pred in predictions:\n",
    "    with open(result_path, \"a\") as file:\n",
    "        file.write(pred + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textsummary",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
