{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "T5 TPU Tensorflow ",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d769aca09c00440d9d7662937d822a8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e8a6a38947ea4b5b937017008245bee7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4107acc3cf044a4abaedd22234eadfe7",
              "IPY_MODEL_21d46a1f7a9f41d890efa0b5a1348810"
            ]
          }
        },
        "e8a6a38947ea4b5b937017008245bee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4107acc3cf044a4abaedd22234eadfe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9ab13c14f30a4460a28ef8a80182c161",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1199,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1199,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_489cc75b406449cfbc800f47b006972a"
          }
        },
        "21d46a1f7a9f41d890efa0b5a1348810": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_876bf16f3dd84a158a99953efa702c26",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.20k/1.20k [00:00&lt;00:00, 2.96kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05bd04a9c018498ba676c47b6715d88b"
          }
        },
        "9ab13c14f30a4460a28ef8a80182c161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "489cc75b406449cfbc800f47b006972a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "876bf16f3dd84a158a99953efa702c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05bd04a9c018498ba676c47b6715d88b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b207d0086f194939a12fd3c935c15fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a7801ca38f564e8da45ed9d808e9183d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4df95b223cb6460e8594d0068eb039f5",
              "IPY_MODEL_1b321b6e3e21497c82c0cec2884f4b77"
            ]
          }
        },
        "a7801ca38f564e8da45ed9d808e9183d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4df95b223cb6460e8594d0068eb039f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_470a88e05bdd4cda94787bb820617c97",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 892146080,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 892146080,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f67c00409fd44619bad9f06c9268e65e"
          }
        },
        "1b321b6e3e21497c82c0cec2884f4b77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_407e078eec7742ed804ef08c393df1e9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 892M/892M [00:14&lt;00:00, 62.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_722b910833dd4d6aac380981efc7be2a"
          }
        },
        "470a88e05bdd4cda94787bb820617c97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f67c00409fd44619bad9f06c9268e65e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "407e078eec7742ed804ef08c393df1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "722b910833dd4d6aac380981efc7be2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGqVkG2-7qfu",
        "colab_type": "text"
      },
      "source": [
        "# T5 TPU Tensorflow "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZIeAC0_tGXj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "a0b37ebc-f1e9-4ecf-c880-3c246fe55737"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFkyo148RDH_",
        "colab_type": "text"
      },
      "source": [
        "### Imports\n",
        "\n",
        "We'll only be importing the components that we'll use during this tutorial: the TensorFlow model alongside the model specific tokenizer. The last two imports will manage the pre-processing of our data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EhpauvOIJzzf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cc8aef15-6035-4ace-8647-eb70a0bed099"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "import os\n",
        "from transformers import ( \n",
        "    T5Tokenizer, \n",
        "    TFT5Model, \n",
        "    TFT5ForConditionalGeneration\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB9CLi1ovDxc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 8\n",
        "\n",
        "SHUFFEL_SIZE = 1024\n",
        "\n",
        "learning_rate = 3e-5\n",
        "\n",
        "model_size = \"t5-base\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jzr0z5K0ECUC",
        "colab_type": "text"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP0QxTsyAV8l",
        "colab_type": "text"
      },
      "source": [
        "### Importing the data\n",
        "\n",
        "We'll use the handy `tensorflow_datasets` package to import our data. As we are using a TPU we do not have access to our local filesystem, we therefore use a Google Cloud Platform bucket to save our data.\n",
        "\n",
        "**You will not be able to use our bucket for this notebook. Please create your own and replace the string corresponding to the bucket.**\n",
        "\n",
        "The data is handled exactly the same way as in the previous tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfh2pE8TvkCD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "outputId": "5569032e-9020-4ef1-8b55-88260162b94c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH7bJP_fvkFR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_size)\n",
        "pad_token_id = tokenizer.pad_token_id\n",
        "prefix = \"summarize: \"\n",
        "\n",
        "def transfrom(x):\n",
        "    x = \" \".join(x.split(\"; \")[1:])\n",
        "    x = re.sub(\"'(.*)'\", r\"\\1\", x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def tokenize_articles(text):\n",
        "    ids = tokenizer.encode_plus((model.config.prefix + text), return_tensors=\"tf\", max_length=512, pad_to_max_length=True) \n",
        "    return tf.squeeze(ids['input_ids']), tf.squeeze(ids['attention_mask'])\n",
        "        \n",
        "def tokenize_highlights(text):\n",
        "    y = tokenizer.encode(text, return_tensors=\"tf\", max_length=150, pad_to_max_length=True)\n",
        "    y = tf.squeeze(y)\n",
        "    y_ids = y[:-1]\n",
        "    lm_labels = tf.identity(y[1:])\n",
        "    lm_labels = tf.where(tf.equal(y[1:],pad_token_id), -100, lm_labels)  \n",
        "\n",
        "    return y, y_ids, lm_labels\n",
        "\n",
        "\n",
        "def get_data(name):\n",
        "    article_path = \"/gdrive/My Drive/cnn_daily_mail/%s/articles_german\" % name\n",
        "    highlights_path = \"/gdrive/My Drive/cnn_daily_mail/%s/highlights_german\" % name\n",
        "\n",
        "    articles = [transfrom(x.rstrip()) for x in open(article_path).readlines()]\n",
        "    highlights = [transfrom(x.rstrip()) for x in open(highlights_path).readlines()]\n",
        "    return articles, highlights\n",
        "    \n",
        "    \n",
        "def get_tokinized_ds(articles, highlights):\n",
        "    x = [] \n",
        "    x_mask = []\n",
        "    for x_i in articles:\n",
        "        t1, t2 = tokenize_articles(x_i)\n",
        "        x.append(t1)\n",
        "        x_mask.append(t2)\n",
        "        \n",
        "    y = []\n",
        "    y_ids = [] \n",
        "    y_labels = []\n",
        "    for y_i in highlights:\n",
        "        t1, t2, t3 = tokenize_highlights(y_i)\n",
        "        y.append(t1)\n",
        "        y_ids.append(t2)\n",
        "        y_labels.append(t3)\n",
        "        \n",
        "        \n",
        "    return x, x_mask, y, y_ids, y_labels\n",
        "\n",
        "def get_translated_ds(name):\n",
        "    articles, highlights = get_data(name)\n",
        "    return get_tokinized_ds(articles, highlights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "paVbPSEVvkLa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val = get_translated_ds(\"val\")\n",
        "test = get_translated_ds(\"test\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSJ4Q--V0YjA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_ds = tf.data.Dataset.from_tensor_slices(val)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(test)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6tea-6XBEag",
        "colab_type": "text"
      },
      "source": [
        "### Serialization\n",
        "\n",
        "Here we are using [TFRecord alongside tf.Example](https://www.tensorflow.org/tutorials/load_data/tfrecord) as a way to read data efficiently. Feeding data to a TPU can very easily be a bottleneck, we therefore store our data in a file that can be used during training.\n",
        "\n",
        "**Unless you change the bucket to your own, you will not be able to run this cell as we have not given public access to write on our public folder. If you change this cell to your own bucket in order to run it, you will have to change the URL from which you download the TFRecord to your bucket URL.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2GRMvxxBExe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "e8943613-18d5-4e2e-c8af-2bcba70c2ac9"
      },
      "source": [
        "skip = True\n",
        "drive_path = \"/gdrive/My Drive/cnn_daily_mail\"\n",
        "if not skip:\n",
        "    # Prepare tf.Examples and tf.Features and write them as TFRecords\n",
        "    def save_tfrecord_to_bucket(features_dataset, gdrive_folder, file_name):\n",
        "        with tf.compat.v1.python_io.TFRecordWriter(f\"{gdrive_folder}/{file_name}.tfrecord\") as tfwriter:\n",
        "            for train_feature in features_dataset:\n",
        "                x, x_mask, y, y_ids, y_labels = train_feature\n",
        "                feature_key_value_pair = {\n",
        "                    'x': tf.train.Feature(int64_list=tf.train.Int64List(value=x)),\n",
        "                    'x_mask': tf.train.Feature(int64_list=tf.train.Int64List(value=x_mask)),\n",
        "                    'y': tf.train.Feature(int64_list=tf.train.Int64List(value=y)),\n",
        "                    'y_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=y_ids)),\n",
        "                    'y_labels': tf.train.Feature(int64_list=tf.train.Int64List(value=y_labels))\n",
        "                }\n",
        "                features = tf.train.Features(feature=feature_key_value_pair)\n",
        "                example = tf.train.Example(features=features)\n",
        "\n",
        "                tfwriter.write(example.SerializeToString())\n",
        "        print(f\"Saved {file_name}.\")\n",
        "\n",
        "    save_tfrecord_to_bucket(val_ds, drive_path, \"val_cnn_daily_mail\")\n",
        "    save_tfrecord_to_bucket(test_ds, drive_path, \"test_cnn_daily_mail\")\n",
        "    save_tfrecord_to_bucket(train_ds, drive_path, \"train_cnn_daily_mail\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved val_cnn_daily_mail.\n",
            "Saved test_cnn_daily_mail.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jShcjelNEFq0",
        "colab_type": "text"
      },
      "source": [
        "# Building the training system"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IX4SPt3mHf0L",
        "colab_type": "text"
      },
      "source": [
        "## Strategy\n",
        "\n",
        "We make use of TensorFlow's strategies, which handle the data distribution as well as the distributed training that happens on the devices available. In this example we'll be using a `MirroredStrategy` which can be used to train on a multiple GPUs in a distributed manner. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17Bnz94tuBFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "cf1aaa93-0c81-481c-efa9-3b9803b0f781"
      },
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:absl:Entering into master device scope: /job:worker/replica:0/task:0/device:CPU:0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.91.63.162:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.91.63.162:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.tpu.topology.Topology at 0x7f9fc963ae10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mIc_Ue7HWBm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "outputId": "e5e5d3cf-0897-4d7e-eb32-442d71f43bd1"
      },
      "source": [
        "strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "print(\"Number of accelerators: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Number of accelerators:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t6ihoFbKoOB",
        "colab_type": "text"
      },
      "source": [
        "## Loading the Dataset with the strategy\n",
        "\n",
        "Here we define a batch size for each replica. We set it to be a multiple of 8 to best leverage the systolic array as defined in the [Google TPU performance guide](https://cloud.google.com/tpu/docs/performance-guide#rule_of_thumb_pick_efficient_values_for_batch_and_feature_dimensions)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfwCFAt9_iCD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE_PER_REPLICA = 6\n",
        "GLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n",
        "EPOCHS = 5\n",
        "\n",
        "MAX_ARTICLE_LEN = 512\n",
        "MAX_HIGHLIGHT_LEN = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d4j3dIqUbXZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e75e4ec8-a56d-4051-e393-a1ac80f9516b"
      },
      "source": [
        "GLOBAL_BATCH_SIZE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TBaFqenUXq8",
        "colab_type": "text"
      },
      "source": [
        "### Retrieving the TFRecord dataset\n",
        "\n",
        "The TFRecord dataset is now entirely processed and ready to be used as input by our training loop. We load it, shuffle it and batch it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmMlC1i0COBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bucket = \"gs://tpu-bucket-cnn-daily-mail\"\n",
        "\n",
        "def get_tfrecord_dataset(drive_path, file_name):\n",
        "    features = {\n",
        "        'x': tf.io.FixedLenFeature([MAX_ARTICLE_LEN], tf.int64),\n",
        "        'x_mask': tf.io.FixedLenFeature([MAX_ARTICLE_LEN], tf.int64),\n",
        "        'y': tf.io.FixedLenFeature([MAX_HIGHLIGHT_LEN], tf.int64),\n",
        "        'y_ids': tf.io.FixedLenFeature([MAX_HIGHLIGHT_LEN - 1], tf.int64),\n",
        "        'y_labels': tf.io.FixedLenFeature([MAX_HIGHLIGHT_LEN - 1], tf.int64),\n",
        "    }\n",
        "\n",
        "    dataset = tf.data.TFRecordDataset(f\"{drive_path}/{file_name}.tfrecord\")\n",
        "\n",
        "    # Taken from the TensorFlow models repository: https://github.com/tensorflow/models/blob/befbe0f9fe02d6bc1efb1c462689d069dae23af1/official/nlp/bert/input_pipeline.py#L24\n",
        "    def decode_record(record, features):\n",
        "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
        "        example = tf.io.parse_single_example(record, features)\n",
        "\n",
        "        # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n",
        "        # So cast all int64 to int32.\n",
        "        for name in list(example.keys()):\n",
        "            t = example[name]\n",
        "            if t.dtype == tf.int64:\n",
        "                t = tf.cast(t, tf.int32)\n",
        "            example[name] = t\n",
        "        return example\n",
        "\n",
        "\n",
        "    def select_data_from_record(record):\n",
        "        return record['x'], record['x_mask'], record['y'], record['y_ids'], record['y_labels']\n",
        "\n",
        "\n",
        "    dataset = dataset.map(lambda record: decode_record(record, features))\n",
        "    dataset = dataset.map(select_data_from_record)\n",
        "    dataset = dataset.shuffle(100)\n",
        "    return dataset.batch(GLOBAL_BATCH_SIZE)\n",
        "\n",
        "train_dataset = get_tfrecord_dataset(bucket, \"train_cnn_daily_mail\")\n",
        "train_dataset.prefetch(1024)\n",
        "\n",
        "validation_dataset = get_tfrecord_dataset(bucket, \"val_cnn_daily_mail\")\n",
        "test_dataset = get_tfrecord_dataset(bucket, \"test_cnn_daily_mail\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkXR1MK0J7Zp",
        "colab_type": "text"
      },
      "source": [
        "There is an additional step here to distribute the dataset among the different TPU cores. We make use of a strategy method to do so.\n",
        "\n",
        "Every item held in the dataset (which is a batched dataset) will now be split over the TPU workers. As the TPU we're using has 8 workers and our batch is of size 64, every example will be evenly split in batches of (64 / 8 =) 8 and distributed across workers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv2zz8vYJ7vh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\n",
        "validation_dist_dataset = strategy.experimental_distribute_dataset(validation_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmC9J6brHN0B",
        "colab_type": "text"
      },
      "source": [
        "## Model creation\n",
        "\n",
        "We create a function that will instantiate a new model when called."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1C-9yTS2GTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model_fn():\n",
        "    return TFT5ForConditionalGeneration.from_pretrained(model_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wS1dc5mvHXNa",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameters initialization\n",
        "\n",
        "While in the strategy's scope, we define a sparse categorical crossentropy loss. We define a method `compute_loss` which will be called to compute the loss between the model's prediction and the expected result (or label).\n",
        "\n",
        "In order to measure the accuracy during training and evaluation, we define two metrics which are both sparse categorical accuracy.\n",
        "\n",
        "Finally, we initialize a model and create an optimizer object using the Adam optimizer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rItpKUam2JSb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207,
          "referenced_widgets": [
            "d769aca09c00440d9d7662937d822a8f",
            "e8a6a38947ea4b5b937017008245bee7",
            "4107acc3cf044a4abaedd22234eadfe7",
            "21d46a1f7a9f41d890efa0b5a1348810",
            "9ab13c14f30a4460a28ef8a80182c161",
            "489cc75b406449cfbc800f47b006972a",
            "876bf16f3dd84a158a99953efa702c26",
            "05bd04a9c018498ba676c47b6715d88b",
            "b207d0086f194939a12fd3c935c15fc4",
            "a7801ca38f564e8da45ed9d808e9183d",
            "4df95b223cb6460e8594d0068eb039f5",
            "1b321b6e3e21497c82c0cec2884f4b77",
            "470a88e05bdd4cda94787bb820617c97",
            "f67c00409fd44619bad9f06c9268e65e",
            "407e078eec7742ed804ef08c393df1e9",
            "722b910833dd4d6aac380981efc7be2a"
          ]
        },
        "outputId": "3fe54033-7240-497d-9b74-b77bf24835c4"
      },
      "source": [
        "with strategy.scope():\n",
        "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(reduction=tf.keras.losses.Reduction.NONE, from_logits=True)\n",
        "\n",
        "    def compute_loss(labels, predictions):\n",
        "        per_example_loss = loss_object(labels, predictions)\n",
        "        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n",
        "\n",
        "    test_loss_metric = tf.keras.metrics.Mean(name='test_loss')\n",
        "    test_accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "    train_loss_metric = tf.keras.metrics.Mean('training_loss', dtype=tf.float32)\n",
        "    train_accuracy_metric = tf.keras.metrics.SparseCategoricalAccuracy('training_accuracy')\n",
        "    \n",
        "    model = model_fn()\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d769aca09c00440d9d7662937d822a8f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1199.0, style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b207d0086f194939a12fd3c935c15fc4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=892146080.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:transformers.modeling_tf_utils:All model checkpoint weights were used when initializing TFT5ForConditionalGeneration.\n",
            "\n",
            "WARNING:transformers.modeling_tf_utils:All the weights of TFT5ForConditionalGeneration were initialized from the model checkpoint at t5-base.\n",
            "If your task is similar to the task the model of the ckeckpoint was trained on, you can already use TFT5ForConditionalGeneration for predictions without further training.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIzuZKDMIuft",
        "colab_type": "text"
      },
      "source": [
        "## Steps\n",
        "\n",
        "We create two functions that will be called during the training and test steps. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZIqCzhL2R6z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with strategy.scope():\n",
        "    def train_step(inputs):\n",
        "        input_ids, input_mask, y, y_ids, lm_labels = inputs\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = model(input_ids, attention_mask=input_mask, decoder_input_ids=y_ids, lm_labels=lm_labels, training=True)[0]  # Gather only the outputs of the text-classification head\n",
        "            loss = compute_loss(y[:, 1:], predictions)\n",
        "\n",
        "        gradients = tape.gradient(loss, model.trainable_variables)\n",
        "\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "        train_loss_metric.update_state(loss)\n",
        "        train_accuracy_metric.update_state(y[:, 1:], predictions)\n",
        "\n",
        "    def test_step(inputs):\n",
        "        input_ids, input_mask, y, y_ids, lm_labels = inputs\n",
        "\n",
        "        predictions = model(input_ids, attention_mask=input_mask, decoder_input_ids=y_ids, lm_labels=lm_labels, training=False)[0]  # Gather only the outputs of the text-classification head\n",
        "        t_loss = compute_loss(y[:, 1:], predictions)\n",
        "\n",
        "        test_loss_metric.update_state(t_loss)\n",
        "        test_accuracy_metric.update_state(y[:, 1:], predictions)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqhnTfbEJ9fa",
        "colab_type": "text"
      },
      "source": [
        "## Training & Evaluation\n",
        "\n",
        "Finally, using all the previously defined attributes, we create two traced tf.function which will execute the training and test steps in a distributed manner. There is no need for them to return anything as the metrics will directly be updated in the steps described beforehand.\n",
        "\n",
        "We loop over the number of epochs, training the model and evaluating it at the end of each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_chN1Sy3IXn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "outputId": "0f70b4ea-edfb-4ca6-96e1-9f5076f56db7"
      },
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "with strategy.scope():\n",
        "    @tf.function\n",
        "    def distributed_train_step(dataset):\n",
        "        strategy.run(train_step, args=(dataset,))\n",
        " \n",
        "\n",
        "    @tf.function\n",
        "    def distributed_test_step(dataset):\n",
        "        strategy.run(test_step, args=(dataset,))\n",
        "\n",
        "\n",
        "    global_step = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "        total_loss = 0.0\n",
        "        training_steps = 10\n",
        "        epoch_step = 0\n",
        "        print_every = 1000\n",
        "\n",
        "        ### Training loop ###\n",
        "        for tensor in tqdm(train_dist_dataset, desc=\"Training\"):\n",
        "            distributed_train_step(tensor)  \n",
        "\n",
        "            train_loss = train_loss_metric.result().numpy().astype(float)\n",
        "            train_accuracy = train_accuracy_metric.result().numpy()\n",
        "\n",
        "            global_step += 1\n",
        "            epoch_step += 1\n",
        "\n",
        "            if epoch_step % print_every == 0:\n",
        "                print(f\"Training step {epoch_step} Accuracy: {train_accuracy}, Training loss: {train_loss}\")\n",
        "\n",
        "\n",
        "        ### Test loop ###\n",
        "        for tensor in tqdm(validation_dist_dataset, desc=\"Evaluating\"):\n",
        "            distributed_test_step(tensor)\n",
        "            \n",
        "        \n",
        "        ### Output results ###\n",
        "        test_accuracy = test_accuracy_metric.result().numpy()\n",
        "        test_loss = test_loss_metric.result().numpy()\n",
        "        print(f'Epoch: [{epoch}] Validation accuracy = {test_accuracy}')\n",
        "\n",
        "        ### Reset metrics ###\n",
        "        test_loss_metric.reset_states()\n",
        "        train_accuracy_metric.reset_states()\n",
        "        train_loss_metric.reset_states()\n",
        "        test_accuracy_metric.reset_states()\n",
        "        epoch_step = 0\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rTraining: 0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-1bdc93bf7e63>:6: StrategyBase.experimental_run_v2 (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "renamed to `run`\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-1bdc93bf7e63>:6: StrategyBase.experimental_run_v2 (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "renamed to `run`\n",
            "Training: 1000it [10:11,  2.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 1000 Accuracy: 0.6948304176330566, Training loss: 31.317729949951172\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 2000it [17:51,  2.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 2000 Accuracy: 0.7141307592391968, Training loss: 28.346038818359375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 3000it [25:29,  2.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 3000 Accuracy: 0.723595142364502, Training loss: 26.952781677246094\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 4000it [33:09,  2.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 4000 Accuracy: 0.7301008105278015, Training loss: 26.04168701171875\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 5000it [40:46,  2.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 5000 Accuracy: 0.7349156737327576, Training loss: 25.38692855834961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 5982it [49:56,  2.00it/s]\n",
            "Evaluating: 279it [01:20,  3.47it/s]\n",
            "Training: 0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [0] Validation accuracy = 0.7656062245368958\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 1000it [07:39,  2.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 1000 Accuracy: 0.7605858445167542, Training loss: 21.97714614868164\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 2000it [15:18,  2.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 2000 Accuracy: 0.7610371112823486, Training loss: 21.90743637084961\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 3000it [22:56,  2.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 3000 Accuracy: 0.7617295980453491, Training loss: 21.813257217407227\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 4000it [30:35,  2.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 4000 Accuracy: 0.7626721262931824, Training loss: 21.69682502746582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 5000it [38:14,  2.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 5000 Accuracy: 0.7635508179664612, Training loss: 21.592601776123047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 5982it [45:45,  2.18it/s]\n",
            "Evaluating: 279it [00:43,  6.47it/s]\n",
            "Training: 0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [1] Validation accuracy = 0.7739362716674805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 1000it [07:42,  2.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 1000 Accuracy: 0.7699467539787292, Training loss: 20.833740234375\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 2000it [15:19,  2.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 2000 Accuracy: 0.7697618007659912, Training loss: 20.84115219116211\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 3000it [23:03,  2.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 3000 Accuracy: 0.769922137260437, Training loss: 20.804471969604492\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 4000it [30:46,  2.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 4000 Accuracy: 0.7704637050628662, Training loss: 20.73806381225586\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 5000it [38:24,  2.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 5000 Accuracy: 0.770969808101654, Training loss: 20.67778205871582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 5982it [45:53,  2.17it/s]\n",
            "Evaluating: 279it [00:42,  6.62it/s]\n",
            "Training: 0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [2] Validation accuracy = 0.778163492679596\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 1000it [07:39,  2.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 1000 Accuracy: 0.7751995325088501, Training loss: 20.200170516967773\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 2000it [15:18,  2.20it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 2000 Accuracy: 0.774742603302002, Training loss: 20.23051643371582\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 3000it [22:56,  2.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 3000 Accuracy: 0.774769127368927, Training loss: 20.21131706237793\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 4000it [30:37,  2.18it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 4000 Accuracy: 0.7751159071922302, Training loss: 20.16559600830078\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 5000it [38:20,  2.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 5000 Accuracy: 0.7754877805709839, Training loss: 20.121145248413086\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 5982it [45:57,  2.17it/s]\n",
            "Evaluating: 279it [00:43,  6.38it/s]\n",
            "Training: 0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [3] Validation accuracy = 0.780969500541687\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 1000it [07:47,  2.10it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 1000 Accuracy: 0.7786505818367004, Training loss: 19.749431610107422\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 2000it [15:32,  2.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 2000 Accuracy: 0.7782138586044312, Training loss: 19.78450584411621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 3000it [23:21,  2.16it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 3000 Accuracy: 0.778134822845459, Training loss: 19.780961990356445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 4000it [31:08,  2.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 4000 Accuracy: 0.7784538865089417, Training loss: 19.744007110595703\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 5000it [38:55,  2.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training step 5000 Accuracy: 0.7787538170814514, Training loss: 19.709964752197266\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Training: 5982it [46:34,  2.14it/s]\n",
            "Evaluating: 279it [00:43,  6.40it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: [4] Validation accuracy = 0.7828335762023926\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu6x9gKla2AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kk0H6POH1Z6b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ckpt_file = os.path.join(bucket, \"checkpoint.ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3qpMpDAihqi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights(ckpt_file) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ap2-FMqd3mN5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "23de6a55-888d-4606-8ae5-896359d3b408"
      },
      "source": [
        "model.load_weights(ckpt_file)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f9fbb8e6c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    }
  ]
}