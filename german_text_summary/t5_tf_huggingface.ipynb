{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Rv_DlM62S3aC"
   },
   "source": [
    "# Text Summary with T5 from Huggingface Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DckiD07HU32-"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import T5Tokenizer, TFT5Model, TFT5ForConditionalGeneration\n",
    "import tensorflow_datasets as tfds\n",
    "import time\n",
    "import os\n",
    "import re\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2QD9xlq6S3aF"
   },
   "source": [
    "### Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_x49QLWNT5XK"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "\n",
    "SHUFFEL_SIZE = 1024\n",
    "\n",
    "learning_rate = 3e-5\n",
    "\n",
    "model_size = \"t5-small\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8BMV9u6YS3aI"
   },
   "source": [
    "## Define Pretrained Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163,
     "referenced_widgets": [
      "1385e9128ddd470ea5c0f16d250bbcd8",
      "1d6442ae39a84745ba549fe97f696d79",
      "a740701578a14ad78f06743b0b8a5747",
      "9461cc70cbb04b0cac331315a4f9e0cb",
      "b9ae4ab518864c55864eff4df556d9fd",
      "4b7c493cb7f840cdaaa20c5095fde3b9",
      "5fd8fdadae6540c38ee4e7db83319feb",
      "06d3777c2f65423f8cba1d52a1d4f74f",
      "5533dafcd9134a43b61225a9e34aab0a",
      "0aeec3fcc7c74505be88c7420bdc4c0a",
      "97e99b21b2a04818a151ca7b771bed55",
      "9741c172eff4470b87abdb31447e6dc9",
      "42041fcda1f84a68acdd52e9d88e247d",
      "72f82ffa86614c9080a69aeea28fda40",
      "02b07ce66df5479083431319e0a4c38d",
      "e0b4d78f8721471e815e7e720d5f4e9c",
      "45af478c9ac84248a3e82fd4b630059b",
      "826d94a4f69d43d9b99cfc485b03ae59",
      "4c6bef2558c34db08d886d4c39f47610",
      "26d0a25b947142c59a59289c82011f85",
      "f8b6a900efe14d4894cabe8cc950d0eb",
      "6837c02ba1694392b9d4ceb74e7ab12f",
      "6c1b85e5f3f14fd19653f17c9972defc",
      "8883b473280c46f28444a5eda5819037"
     ]
    },
    "colab_type": "code",
    "id": "BVinRzgfIdkr",
    "outputId": "03e07082-ccf7-4e11-a82c-438f10ddb937"
   },
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(model_size)\n",
    "\n",
    "model = TFT5ForConditionalGeneration.from_pretrained(model_size)\n",
    "\n",
    "task_specific_params = model.config.task_specific_params\n",
    "if task_specific_params is not None:\n",
    "    model.config.update(task_specific_params.get(\"summarization\", {}))\n",
    "\n",
    "pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 250
    },
    "colab_type": "code",
    "id": "aI7FIzmmnA5l",
    "outputId": "0db7d1c0-3b95-41f3-c58a-eb7ded612641"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_t5for_conditional_generation\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "shared (TFSharedEmbeddings)  multiple                  16449536  \n",
      "_________________________________________________________________\n",
      "encoder (TFT5MainLayer)      multiple                  18881280  \n",
      "_________________________________________________________________\n",
      "decoder (TFT5MainLayer)      multiple                  25176064  \n",
      "=================================================================\n",
      "Total params: 60,506,880\n",
      "Trainable params: 60,506,880\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=1e-08)\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n",
    "\n",
    "val_loss = tf.keras.metrics.Mean(name='val_loss')\n",
    "val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='val_accuracy')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "47-CDTNdS3aM"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dq96SqWXUIld"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_size)\n",
    "pad_token_id = tokenizer.pad_token_id\n",
    "prefix = \"summarize: \"\n",
    "\n",
    "def transfrom(x):\n",
    "    x = \" \".join(x.split(\"; \")[1:])\n",
    "    x = re.sub(\"'(.*)'\", r\"\\1\", x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def tokenize_articles(text):\n",
    "    ids = tokenizer.encode_plus((prefix + text), return_tensors=\"tf\", max_length=512, pad_to_max_length=True) \n",
    "    return tf.squeeze(ids['input_ids']), tf.squeeze(ids['attention_mask'])\n",
    "        \n",
    "def tokenize_highlights(text):\n",
    "    y = tokenizer.encode(text, return_tensors=\"tf\", max_length=150, pad_to_max_length=True)\n",
    "    y = tf.squeeze(y)\n",
    "    y_ids = y[:-1]\n",
    "    lm_labels = tf.identity(y[1:])\n",
    "    lm_labels = tf.where(tf.equal(y[1:],pad_token_id), -100, lm_labels)  \n",
    "\n",
    "    return y, y_ids, lm_labels\n",
    "\n",
    "\n",
    "def get_data(name):\n",
    "    article_path = \"../data/%s/articles_german\" % name\n",
    "    highlights_path = \"../data/%s/highlights_german\" % name\n",
    "\n",
    "    articles = [transfrom(x.rstrip()) for x in open(article_path).readlines()]\n",
    "    highlights = [transfrom(x.rstrip()) for x in open(highlights_path).readlines()]\n",
    "    return articles, highlights\n",
    "    \n",
    "    \n",
    "def get_tokinized_ds(articles, highlights):\n",
    "    x = [] \n",
    "    x_mask = []\n",
    "    for x_i in articles:\n",
    "        t1, t2 = tokenize_articles(x_i)\n",
    "        x.append(t1)\n",
    "        x_mask.append(t2)\n",
    "        \n",
    "    y = []\n",
    "    y_ids = [] \n",
    "    y_labels = []\n",
    "    for y_i in highlights:\n",
    "        t1, t2, t3 = tokenize_highlights(y_i)\n",
    "        y.append(t1)\n",
    "        y_ids.append(t2)\n",
    "        y_labels.append(t3)\n",
    "        \n",
    "        \n",
    "    return x, x_mask, y, y_ids, y_labels\n",
    "\n",
    "def get_translated_ds(name):\n",
    "    articles, highlights = get_data(name)\n",
    "    return get_tokinized_ds(articles, highlights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "x34Dpv8cfYKU",
    "outputId": "cff39866-91bc-44f8-f45a-807065f22a1b"
   },
   "outputs": [],
   "source": [
    "train = get_translated_ds(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved train_cnn_daily_mail.\n"
     ]
    }
   ],
   "source": [
    "skip = False\n",
    "drive_path = \"../data\"\n",
    "if not skip:\n",
    "    # Prepare tf.Examples and tf.Features and write them as TFRecords\n",
    "    def save_tfrecord_to_bucket(features_dataset, gdrive_folder, file_name):\n",
    "        with tf.compat.v1.python_io.TFRecordWriter(f\"{gdrive_folder}/{file_name}.tfrecord\") as tfwriter:\n",
    "            for train_feature in features_dataset:\n",
    "                x, x_mask, y, y_ids, y_labels = train_feature\n",
    "                feature_key_value_pair = {\n",
    "                    'x': tf.train.Feature(int64_list=tf.train.Int64List(value=x)),\n",
    "                    'x_mask': tf.train.Feature(int64_list=tf.train.Int64List(value=x_mask)),\n",
    "                    'y': tf.train.Feature(int64_list=tf.train.Int64List(value=y)),\n",
    "                    'y_ids': tf.train.Feature(int64_list=tf.train.Int64List(value=y_ids)),\n",
    "                    'y_labels': tf.train.Feature(int64_list=tf.train.Int64List(value=y_labels))\n",
    "                }\n",
    "                features = tf.train.Features(feature=feature_key_value_pair)\n",
    "                example = tf.train.Example(features=features)\n",
    "\n",
    "                tfwriter.write(example.SerializeToString())\n",
    "        print(f\"Saved {file_name}.\")\n",
    "\n",
    "    save_tfrecord_to_bucket(train_ds, drive_path, \"train_cnn_daily_mail\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13368"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = tf.data.Dataset.from_tensor_slices(val)\n",
    "train_ds = tf.data.Dataset.from_tensor_slices(train)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.data.experimental' has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-c33e47c60c07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"val.tfrecord\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.data.experimental' has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "def write_ds(ds, filename):\n",
    "    writer = tf.data.experimental.TFRecordWriter(filename)\n",
    "    writer.write(ds)\n",
    "    \n",
    "tf.data.experimental.save(val_ds, \"val.tfrecord\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 368
    },
    "colab_type": "code",
    "id": "sGGDx-oMUnRV",
    "outputId": "fe605e45-1c77-4ea5-c5de-2a2281707c20"
   },
   "outputs": [],
   "source": [
    "# train_ds = tf.data.Dataset.from_tensor_slices(train)\\\n",
    "#     .map(map_func)\\\n",
    "#     .shuffle(SHUFFEL_SIZE)\\\n",
    "#     .padded_batch(BATCH_SIZE, padded_shapes=([512],[512],[149],[149]))\\\n",
    "#     .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds\\\n",
    "    .shuffle(SHUFFEL_SIZE)\\\n",
    "    .padded_batch(BATCH_SIZE, padded_shapes=([512],[512],[149],[149]))\\\n",
    "    .prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# test_ds = tf.data.Dataset.from_tensor_slices(get_translated_ds(\"test\"))\\\n",
    "# .shuffle(SHUFFEL_SIZE)\\\n",
    "# .padded_batch(BATCH_SIZE, padded_shapes=([512],[512],[149],[149]))\\\n",
    "# .prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wNXvA5Yfaijx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(2, 512), dtype=int32, numpy=\n",
      "array([[21603,    10,     3, ...,  6711,    15,    10],\n",
      "       [    1,     1,     1, ...,     1,     1,     1]], dtype=int32)>, <tf.Tensor: shape=(2, 149), dtype=int32, numpy=\n",
      "array([[    3,     7,  1427,    21,  6216,     6,   266,     3,  8104,\n",
      "        15091,    77,    64,     3,    17,  6125,  2558,    77,     6,\n",
      "           67,    16,   177,  1283,    49,    64,   943,    49,     3,\n",
      "         8375,    35,    16,  4183,     7,    64,   814,    35,   193,\n",
      "         5453,    51,    67,    90,    77,   210,   232,     3, 12228,\n",
      "           15,     6,  2213,   115,   183,  9996,     3,    51,  3185,\n",
      "          172,     5,    21,  6216,     6,    74,    35,   873,  5808,\n",
      "           17,     7,  4350,     3,  8682,   760,   630,  2572,  3186,\n",
      "          615,     6,     3, 28875,    15,  6575,  2995,   177,     3,\n",
      "          157,    60,   115,     7,     5,    21,  6216,     6,    67,\n",
      "          403,     3,     7,   152,    67,   839,     3, 26548,     6,\n",
      "         1177,     3, 20509,   697,    74,     3,   107, 30322,    18,\n",
      "         1967,    60,   155,  6655,     3,    23,    26,     9,     3,\n",
      "           40,   413,    77,    32,     6,    67,   680,    16,     3,\n",
      "        16512,  4046,    35,    16,   814,    35,    36,  6773,    15,\n",
      "            5,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0],\n",
      "       [    7,  1427,    21,  6216,     6,   266,     3,  8104, 15091,\n",
      "           77,    64,     3,    17,  6125,  2558,    77,     6,    67,\n",
      "           16,   177,  1283,    49,    64,   943,    49,     3,  8375,\n",
      "           35,    16,  4183,     7,    64,   814,    35,   193,  5453,\n",
      "           51,    67,    90,    77,   210,   232,     3, 12228,    15,\n",
      "            6,  2213,   115,   183,  9996,     3,    51,  3185,   172,\n",
      "            5,    21,  6216,     6,    74,    35,   873,  5808,    17,\n",
      "            7,  4350,     3,  8682,   760,   630,  2572,  3186,   615,\n",
      "            6,     3, 28875,    15,  6575,  2995,   177,     3,   157,\n",
      "           60,   115,     7,     5,    21,  6216,     6,    67,   403,\n",
      "            3,     7,   152,    67,   839,     3, 26548,     6,  1177,\n",
      "            3, 20509,   697,    74,     3,   107, 30322,    18,  1967,\n",
      "           60,   155,  6655,     3,    23,    26,     9,     3,    40,\n",
      "          413,    77,    32,     6,    67,   680,    16,     3, 16512,\n",
      "         4046,    35,    16,   814,    35,    36,  6773,    15,     5,\n",
      "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
      "         -100,  -100,  -100,  -100,  -100]], dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for i in val_ds.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YnC9jfn6S3aX"
   },
   "source": [
    "## Define Train and Validation Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TnoYzc3eS3aX"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_ids, input_mask, y_ids, lm_labels):\n",
    "    # https://github.com/huggingface/transformers/blob/master/examples/summarization/bart/finetune.py\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        # prediction_scores: (bs, 150, 32128)\n",
    "        # decoder_past_key_value_states: (bs, 512, 512), (bs, 8, 150, 64)\n",
    "        # z: (bs, 512, 512)\n",
    "        predictions, _, _ = model(input_ids, attention_mask=input_mask, decoder_input_ids=y_ids, lm_labels=lm_labels, training=True)\n",
    "        loss = loss_object(y[:, 1:], predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    train_loss(loss)\n",
    "    train_accuracy(y[:, 1:], predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cZ19b6E4S3aZ"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def val_step(input_ids, input_mask, y_ids, lm_labels):\n",
    "    # https://github.com/huggingface/transformers/blob/master/examples/summarization/bart/finetune.py\n",
    "    \n",
    "    predictions, _, _ = model(input_ids, attention_mask=input_mask, decoder_input_ids=y_ids, lm_labels=lm_labels, training=False)\n",
    "    v_loss = loss_object(y[:, 1:], predictions)\n",
    "\n",
    "    val_loss(v_loss)\n",
    "    val_accuracy(y[:, 1:], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WUlJ7uzlS3ab"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "qQZFQvNxpVJw",
    "outputId": "10323332-dd60-40c6-fcec-e0a42af13a09"
   },
   "outputs": [
    {
     "ename": "UnavailableError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    658\u001b[0m         \u001b[0;31m# Fast path for the case `self._structure` is not a nested structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute '_from_compatible_tensor_list'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   1985\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m       \u001b[0;32myield\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    660\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36mfrom_compatible_tensor_list\u001b[0;34m(element_spec, tensor_list)\u001b[0m\n\u001b[1;32m    229\u001b[0m       \u001b[0;32mlambda\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m       element_spec, tensor_list)\n\u001b[0m\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m_from_tensor_list_helper\u001b[0;34m(decode_fn, element_spec, tensor_list)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnum_flat_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m     \u001b[0mflat_ret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnum_flat_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/util/structure.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(spec, value)\u001b[0m\n\u001b[1;32m    228\u001b[0m   return _from_tensor_list_helper(\n\u001b[0;32m--> 229\u001b[0;31m       \u001b[0;32mlambda\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m       element_spec, tensor_list)\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/tensor_spec.py\u001b[0m in \u001b[0;36m_from_compatible_tensor_list\u001b[0;34m(self, tensor_list)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mtensor_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shape\u001b[0;34m(self, shape)\u001b[0m\n\u001b[1;32m   1103\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1104\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1105\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1064\u001b[0m         \u001b[0;31m# `EagerTensor`, in C.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tensor_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorShape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error while creating shape",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mUnavailableError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-657eec4d083a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# For Python 3 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;34m\"\"\"Returns a nested structure of `Tensor`s containing the next element.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_next_internal\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_from_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_compatible_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;31m# Suppress StopIteration *unless* it's the same exception that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mexecution_mode\u001b[0;34m(mode)\u001b[0m\n\u001b[1;32m   1987\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m       \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecutor_old\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1989\u001b[0;31m       \u001b[0mexecutor_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/executor.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;34m\"\"\"Waits for ops dispatched in this executor to finish.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mpywrap_tfe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFE_ExecutorWaitForAllPendingNodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mclear_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnavailableError\u001b[0m: failed to connect to all addresses\nAdditional GRPC error information:\n{\"created\":\"@1595453058.917191833\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":3959,\"referenced_errors\":[{\"created\":\"@1595453058.917188209\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":394,\"grpc_status\":14}]}"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "log_interval = 200\n",
    "for epoch in range(EPOCHS):\n",
    "    # reset metrics\n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    \n",
    "    val_loss.reset_states()\n",
    "    val_accuracy.reset_states()\n",
    "    \n",
    "    val_batches = iter(val_ds)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i, (input_ids, input_mask, y_ids, labels) in enumerate(train_ds):\n",
    "        # training\n",
    "        strategy.run(train_step(input_ids, input_mask, y_ids, labels))\n",
    "        \n",
    "        # validation\n",
    "        if i % log_interval == 0:\n",
    "            x_val, x_mask_val, y_val, y_label = next(val_batches)\n",
    "            strategy.run(val_step(x_val, x_mask_val, y_val, y_label))\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | [{:5d}/{:5d}] | '\n",
    "                  'ms/batch {:5.2f} | '\n",
    "                  'train acc {:5.2f} | val acc {:5.2f} |'\n",
    "                  'loss {:5.2f} | val loss {:5.2f}'.format(\n",
    "                    epoch, i, int(len_train/BATCH_SIZE),\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    train_accuracy.result() * 100, val_accuracy.result() * 100, \n",
    "                    train_loss.result(),  val_loss.result()))\n",
    "            start_time = time.time()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jyZ3-KmjS3ad"
   },
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QrHuVB_KS3ad"
   },
   "source": [
    "### Define Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JD_vwDQ_S3ae"
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from rouge_score import scoring\n",
    "\n",
    "class RougeScore:\n",
    "    '''\n",
    "    mostly from https://github.com/google-research/text-to-text-transfer-transformer/blob/master/t5/evaluation/metrics.py \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, score_keys=None)-> None:\n",
    "        super().__init__()\n",
    "        if score_keys is None:  \n",
    "            self.score_keys = [\"rouge1\", \"rouge2\", \"rougeLsum\"]\n",
    "        \n",
    "        self.scorer = rouge_scorer.RougeScorer(self.score_keys)\n",
    "        self.aggregator = scoring.BootstrapAggregator()\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def prepare_summary(summary):\n",
    "            # Make sure the summary is not bytes-type\n",
    "            # Add newlines between sentences so that rougeLsum is computed correctly.\n",
    "            summary = summary.replace(\" . \", \" .\\n\")\n",
    "            return summary\n",
    "    \n",
    "    def __call__(self, target, prediction):\n",
    "        \"\"\"Computes rouge score.''\n",
    "        Args:\n",
    "        targets: string\n",
    "        predictions: string\n",
    "        \"\"\"\n",
    "\n",
    "        target = self.prepare_summary(target)\n",
    "        prediction = self.prepare_summary(prediction)\n",
    "        \n",
    "        self.aggregator.add_scores(self.scorer.score(target=target, prediction=prediction))\n",
    "\n",
    "        return \n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.rouge_list = []\n",
    "\n",
    "    def result(self):\n",
    "        result = self.aggregator.aggregate()\n",
    "        \n",
    "        for key in self.score_keys:\n",
    "            score_text = \"%s = %.2f, 95%% confidence [%.2f, %.2f]\"%(\n",
    "                key,\n",
    "                result[key].mid.fmeasure*100,\n",
    "                result[key].low.fmeasure*100,\n",
    "                result[key].high.fmeasure*100\n",
    "            )\n",
    "            print(score_text)\n",
    "        \n",
    "        return {key: result[key].mid.fmeasure*100 for key in self.score_keys}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MW3TqyzeS3af"
   },
   "source": [
    "### Compute Rouge Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-0SwShZ9S3ag",
    "outputId": "62618201-2dea-4f67-ea52-d8594220262a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 = 36.45, 95% confidence [35.93, 36.91]\n",
      "rouge2 = 16.47, 95% confidence [16.02, 16.93]\n",
      "rougeLsum = 34.05, 95% confidence [33.53, 34.55]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 36.4493063524424,\n",
       " 'rouge2': 16.471916808516053,\n",
       " 'rougeLsum': 34.052609516834295}"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = []\n",
    "rouge_score = RougeScore()\n",
    "for i, (input_ids, input_mask, y) in enumerate(test_ds):\n",
    "    summaries = model.generate(input_ids=input_ids, attention_mask=input_mask)\n",
    "\n",
    "    pred = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summaries]\n",
    "    real = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in y]\n",
    "    \n",
    "    for pred_sent, real_sent in zip(pred, real):\n",
    "        rouge_score(pred_sent, real_sent)\n",
    "        predictions.append(str(\"pred sentence: \" + pred_sent + \"\\n\\n real sentence: \" + real_sent))\n",
    "        \n",
    "    if i > 100:\n",
    "        # otherwise it will take ages\n",
    "        break\n",
    "\n",
    "\n",
    "rouge_score.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sBES-sqvS3ai"
   },
   "source": [
    "### Predict some Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Lan7mN-S3ai",
    "outputId": "bda67b0f-1a5d-4cce-bcf0-924200516330"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "pred sentence: A cave photographer, john spies, 59, captured the sheer magnificence of the vast, yet intricate, underground wonderland . xe bang fai river caves feature imposing stalagmitemade of mineral deposits . the cave is only able to be safely accessed during the dry season from november to april and during this time the water is clear and deep with a rich green hue . in 2008, an expedition led to the mysterious caves being \n",
      "\n",
      " real sentence: the tham khoun ex cave has 15km of spectacular caves waiting to be explore by kayak . explorers can witness the incredible caverns, lake and even the vibrant forest at the entrance . cave photographer john spies captured the labyrinthine chambers to unfold the mystery .\n",
      "------\n",
      "------\n",
      "pred sentence: houston couple, who have not been named, were arguing in the parking lot of an apartment complex . husband admitted to police that during the heat of the argument he tried to drive off in his green chevrolet pickup truck when his wife grabbed the door handle, slipped, and he ran her over . police say that they questioned the man extensively but believe his story and have not filed charges against him . the woman was rushed to memorial hermann hospital southwest where doctors successfully delivered her baby by cesarean section . a friend of the woman's 17-year-old son was told of his mother's death during a phone call at school . she came to the driver's door, she fell and the husband ran her, but they have not yet been named . they were questioned about the incident . but they believe he was crying, and the baby was saved \n",
      "\n",
      " real sentence: her husband admits the pair had been arguing minutes before the accident . she came to the driver's door while her husband drove away and she fell . police say they believe the husband's story and have not charged him . doctors were able to deliver her 36-week-old baby in houston, texas . the pregnant woman, who has not been named, died later in hospital .\n",
      "------\n",
      "------\n",
      "pred sentence: osborne said he wanted a 1980s-style property revolution after years of declining home ownership . he pledged to double the number of people buying their first home . since 2010 there have been 1.2 million first-time purchases and 2.4 million more over the next five years . david cameron said: i believe britain should be a home-owning democracy, that’s the goal English pm: we have acted on every front, we’ll continue to help first time buyers get on the housing ladder every year by 2020 - 'home ownership is an absolutely core conservative belief and aspiration that we support a 80s style property revolution . chancellor wants to double number using government help-to-by schemes and wants at least 2.4m more over five years, mr o'british people can buy a house .\n",
      "\n",
      " real sentence: chancellor pledged to double the number of people buying their first home . since 2010 there have been 1.2 million first-time buyers getting first homes . mr osborne wants at least 2.4 million more over the next five years .\n",
      "------\n",
      "------\n",
      "pred sentence: hannah wilson's body was found in rural brown county, indiana, on friday morning after a night out . daniel messel, 49, was arrested hours later and has been charged in her death . circumstances of her disappearance are 'eerily similar' to the case of 20-year-old spierer, police said . she was last seen at kilroy's sports bar in bloomington with a group of friends on monday . it is not known if she was a student . a cellphone was found near her feet and no criminal charges have been filed in connection with the death of lauren messel . the body of the student has never been found in brown county . police will be looking into the case again . there is no sign of sexual assault . her body has not been found and she was\n",
      "\n",
      " real sentence: police said the circumstances of the disappearances of hannah wilson and lauren spierer are eerily similar spierer, 20, went missing in 2011 after a night partying with friends; her body has never been found and no criminal charges have been filed . wilson's body was found on rural land about 10 miles away last friday and it is believed she died of blunt force trauma . daniel messel, 49, has been arrested in her death after a cellphone at her feet was traced back to him and he had blood inside his car\n",
      "------\n",
      "------\n",
      "pred sentence: zeynab daghastani, 13, was shot and killed on tuesday as she tried to flee a militant-held area of damascus . she was reportedly gunned down by isis snipers in al-yarmouk camp . the teenager was trying to make her way to a nearby neighbourhood controlled by the syrian army . thousands of palestinians have been trying to escape the area since the area fell under is\n",
      "\n",
      " real sentence: zeynab daghastani, 13, reportedly gunned down as she fled yarmouk camp . teen trying to get to nearby yalda district which is not under isis control . yarmouk, on the outskirts of damascus, has been under siege since 2012 . isis seized it ten days ago and have been butchering those trapped there .\n",
      "------\n",
      "------\n",
      "pred sentence: israeli tourist captured the moment a group of baboons robbed a supply truck in tanzania . the 40-second-clip shows the driver standing next to his vehicle . man is forced to retreat as one makes a lunge at him and another jumps into the back of the truck to search for supplies . he makes an attempt to scare the monkey away and eventually it re-emerges . it carries snacks in both its hands and its mouth before scarping\n",
      "\n",
      " real sentence: video was captured at the ngorongoro conservation area in tanzania . israeli tourist filmed a group of baboons approaching a supply truck . as one distracts the driver by lunging at it another jumps into vehicle . before long it re-emerges with its hands and mouth full of snacks . the group of thieves reconvene and run off into the bushes together .\n",
      "------\n",
      "------\n",
      "pred sentence: england captain alastair cook completed a much-needed century on the second morning of englands opening tour match in the west indies . cook resumed on 95 and reached three figures with minimal fuss before retiring out . ian bell arrived at the crease, with batting time more important to the tourists than attempting to force a result in this two-day fixture . ivan bell walked off on 101 from 200 deliveries during day two of the st kitts and nevis invitational xi vs saturday's opening match . the tourists will be able to reach three figures on tuesday . captain resumed a century before retiring on 95 . it was the second day of the tour match at the end of the day - the tourists had to wait until the tourists are unable to make a decision \n",
      "\n",
      " real sentence: alastair cook completed his century on the second morning of action . england captain resumed on 95 and reached three figures before retiring . that allowed ian bell to arrive at the crease as tourists continued to bat .\n",
      "------\n",
      "------\n",
      "pred sentence: kenneth morgan stancil iii, 20, told raleighs wral-tv on wednesday that he killed ron lane earlier this week in north carolina because lane had made sexual advances towards his 16-year-old brother . in a telephone interview from a daytona beach jail, he said lane tried to take advantage of his brother and he was in the proposal to try to and i wasnt going to give a damn if i get life, 'i did what i did, i do anything necessary to take care of my family . he is awaiting extradition from florida to north america . the neo-nazi has no reports of unsolved homicides . police did not immediately return a phone message on th\n",
      "\n",
      " real sentence: suspect kenneth morgan stancil claimed he killed ron lane because the college employee made sexual advances to his 16-year-old brother . the murder suspect gave himself fascist face tattoos . stancil also said he is a neo-nazi who is concerned about the future of white children and hates race-mixing\n",
      "------\n",
      "------\n",
      "pred sentence: a new australian fashion report has named and shamed some of the worst aussie clothing brands . amongst the best performers were etiko, audrey blue, cotton on, h&m and zara . only two of the 59 companies could prove they were paying a full living wage to the workers in two of three production stages of their clothing . a living wage ensures that an employee has enough money to cover the necessities - like food, water, electricity and shelter . the report assessed the labour rights management system of 59 brands and 219 brands operating in australia . it named the worst performers by the 2015 australian clothing brands and their companies - which includes just jeans, portmans and dotti - among the best - including cotton on - and the just group - a country's legally set minimum wage - the only two could prove the\n",
      "\n",
      " real sentence: australian fashion report revealed the australian-sold brands and companies that ignore the exploitation of their overseas workers . lowes, industrie, best & less and the just group - which includes just jeans, portmans and dotti - were some of the worst performers . etiko, audrey blue, cotton on, h&m and zara had some of the best scores . 75 per cent of companies don't know the source of all their fabrics and inputs .\n",
      "------\n",
      "------\n",
      "pred sentence: lindsay lohan, 28, has been living in london for the past year and says she feels 'at home' in the uk . the flame-haired beauty recently spent a stint on the stage, starring in a west end production of david mamet's speed the plow . she has no plans to return to the states for the foreseeable future . ms lohan says she's going back to nyc and la for family and work . it's a big budget for lingerie and a sex appeal, but she has been in the us since she moved across the pond to uk for more than a year . but she doesn't see herself returning to the u.s. and wants to be a part of a series of racy ensembles by moschino .\n",
      "\n",
      " real sentence: lindsay, 28, moved to the uk last spring before making her london stage debut . the former child star has become more famous for her run-ins with the police and the media than anything else in recent years . but lindsay is now vowing to stay in london to grow up she appears in a provocative spread for homme style magazine, having been shot by famed fashion photographer rankin .\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for pred in predictions[:10]:\n",
    "    print(\"------\")\n",
    "    print(pred)\n",
    "    print(\"------\")     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0K1t4JrGS3al"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWu0WlIPS3an"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wVo5KGdWS3ao"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "t5_tf_huggingface.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "textsummary",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02b07ce66df5479083431319e0a4c38d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "06d3777c2f65423f8cba1d52a1d4f74f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0aeec3fcc7c74505be88c7420bdc4c0a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1385e9128ddd470ea5c0f16d250bbcd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a740701578a14ad78f06743b0b8a5747",
       "IPY_MODEL_9461cc70cbb04b0cac331315a4f9e0cb"
      ],
      "layout": "IPY_MODEL_1d6442ae39a84745ba549fe97f696d79"
     }
    },
    "1d6442ae39a84745ba549fe97f696d79": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "26d0a25b947142c59a59289c82011f85": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8883b473280c46f28444a5eda5819037",
      "placeholder": "​",
      "style": "IPY_MODEL_6c1b85e5f3f14fd19653f17c9972defc",
      "value": " 892M/892M [00:19&lt;00:00, 46.9MB/s]"
     }
    },
    "42041fcda1f84a68acdd52e9d88e247d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "45af478c9ac84248a3e82fd4b630059b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_4c6bef2558c34db08d886d4c39f47610",
       "IPY_MODEL_26d0a25b947142c59a59289c82011f85"
      ],
      "layout": "IPY_MODEL_826d94a4f69d43d9b99cfc485b03ae59"
     }
    },
    "4b7c493cb7f840cdaaa20c5095fde3b9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c6bef2558c34db08d886d4c39f47610": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6837c02ba1694392b9d4ceb74e7ab12f",
      "max": 892146080,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8b6a900efe14d4894cabe8cc950d0eb",
      "value": 892146080
     }
    },
    "5533dafcd9134a43b61225a9e34aab0a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_97e99b21b2a04818a151ca7b771bed55",
       "IPY_MODEL_9741c172eff4470b87abdb31447e6dc9"
      ],
      "layout": "IPY_MODEL_0aeec3fcc7c74505be88c7420bdc4c0a"
     }
    },
    "5fd8fdadae6540c38ee4e7db83319feb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6837c02ba1694392b9d4ceb74e7ab12f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c1b85e5f3f14fd19653f17c9972defc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "72f82ffa86614c9080a69aeea28fda40": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "826d94a4f69d43d9b99cfc485b03ae59": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8883b473280c46f28444a5eda5819037": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9461cc70cbb04b0cac331315a4f9e0cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_06d3777c2f65423f8cba1d52a1d4f74f",
      "placeholder": "​",
      "style": "IPY_MODEL_5fd8fdadae6540c38ee4e7db83319feb",
      "value": " 792k/792k [00:00&lt;00:00, 1.69MB/s]"
     }
    },
    "9741c172eff4470b87abdb31447e6dc9": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e0b4d78f8721471e815e7e720d5f4e9c",
      "placeholder": "​",
      "style": "IPY_MODEL_02b07ce66df5479083431319e0a4c38d",
      "value": " 1.20k/1.20k [00:19&lt;00:00, 61.8B/s]"
     }
    },
    "97e99b21b2a04818a151ca7b771bed55": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_72f82ffa86614c9080a69aeea28fda40",
      "max": 1199,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_42041fcda1f84a68acdd52e9d88e247d",
      "value": 1199
     }
    },
    "a740701578a14ad78f06743b0b8a5747": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b7c493cb7f840cdaaa20c5095fde3b9",
      "max": 791656,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b9ae4ab518864c55864eff4df556d9fd",
      "value": 791656
     }
    },
    "b9ae4ab518864c55864eff4df556d9fd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e0b4d78f8721471e815e7e720d5f4e9c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8b6a900efe14d4894cabe8cc950d0eb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
