{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0FMn6DnelFC"
   },
   "source": [
    "# Transformer (NMT) Translation\n",
    "- Based on : https://pytorch.org/hub/pytorch_fairseq_translation/\n",
    "    *Author: Facebook AI (fairseq Team)*\n",
    "\n",
    "## Translate CNN Daily Mail\n",
    "We will translate the English Dataset CNN Daily Mail to German to try German text summarization\n",
    "\n",
    "### Model Description\n",
    "\n",
    "The Transformer, introduced in the paper [Attention Is All You Need][1], is a\n",
    "powerful sequence-to-sequence modeling architecture capable of producing\n",
    "state-of-the-art neural machine translation (NMT) systems.\n",
    "\n",
    "Recently, the fairseq team has explored large-scale semi-supervised training of\n",
    "Transformers using back-translated data, further improving translation quality\n",
    "over the original model. More details can be found in [this blog post][2].\n",
    "\n",
    "\n",
    "### Requirements\n",
    "\n",
    "We require a few additional Python dependencies for preprocessing:\n",
    "-  pip install fastBPE regex requests sacremoses subword_nmt Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gM2_52dLfLwY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 23 10:13:23 2020       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 435.21       Driver Version: 435.21       CUDA Version: 10.1     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  GeForce RTX 208...  Off  | 00000000:08:00.0  On |                  N/A |\r\n",
      "| 35%   40C    P8    24W / 260W |   1018MiB / 11016MiB |      1%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0      1364      G   /usr/lib/xorg/Xorg                           150MiB |\r\n",
      "|    0      1953      G   /usr/lib/xorg/Xorg                           423MiB |\r\n",
      "|    0      2153      G   /usr/bin/gnome-shell                         240MiB |\r\n",
      "|    0      2481      G   ...AAAAAAAAAAAACAAAAAAAAAA= --shared-files   184MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6zPOebvRelFH"
   },
   "source": [
    "### English-to-German Translation\n",
    "\n",
    "Semi-supervised training with back-translation is an effective way of improving\n",
    "translation systems. In the paper [Understanding Back-Translation at Scale][4],\n",
    "we back-translate over 200 million German sentences to use as additional\n",
    "training data. An ensemble of five of these models was the winning submission to\n",
    "the [WMT'18 English-German news translation competition][5].\n",
    "\n",
    "We can further improved this approach through [noisy-channel reranking][6]. More\n",
    "details can be found in [this blog post][7]. An ensemble of models trained with\n",
    "this technique was the winning submission to the [WMT'19 English-German news\n",
    "translation competition][8].\n",
    "\n",
    "To translate from English to German using one of the models from the winning submission:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "22podDrRelFM"
   },
   "source": [
    "### References\n",
    "\n",
    "- [Attention Is All You Need][1]\n",
    "- [Scaling Neural Machine Translation][3]\n",
    "- [Understanding Back-Translation at Scale][4]\n",
    "- [Facebook FAIR's WMT19 News Translation Task Submission][6]\n",
    "\n",
    "\n",
    "[1]: https://arxiv.org/abs/1706.03762\n",
    "[2]: https://code.fb.com/ai-research/scaling-neural-machine-translation-to-bigger-data-sets-with-faster-training-and-inference/\n",
    "[3]: https://arxiv.org/abs/1806.00187\n",
    "[4]: https://arxiv.org/abs/1808.09381\n",
    "[5]: http://www.statmt.org/wmt18/translation-task.html\n",
    "[6]: https://arxiv.org/abs/1907.06616\n",
    "[7]: https://ai.facebook.com/blog/facebook-leads-wmt-translation-competition/\n",
    "[8]: http://www.statmt.org/wmt19/translation-task.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from pathlib import Path\n",
    "from segtok.segmenter import split_single\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_run = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write tfds Dataset to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if first_run:\n",
    "    import tensorflow as tf\n",
    "    import tensorflow_datasets as tfds\n",
    "\n",
    "    cnn_dailymail = tfds.load(name=\"cnn_dailymail\")\n",
    "\n",
    "    train_tfds = cnn_dailymail['train']\n",
    "    test_tfds = cnn_dailymail['test']\n",
    "    val_tfds = cnn_dailymail['validation']\n",
    "\n",
    "    train_ds_iter = tfds.as_numpy(train_tfds)\n",
    "    val_ds_iter = tfds.as_numpy(val_tfds)\n",
    "    test_ds_iter = tfds.as_numpy(test_tfds)\n",
    "\n",
    "\n",
    "    def write_data(iter_dataset, name, path=\"../data/\"):\n",
    "\n",
    "        articles_file = Path(path + name + \"/article\").open(\"w\")\n",
    "        highlights_file = Path(path + name + \"/highlights\").open(\"w\")\n",
    "\n",
    "        for item in iter_dataset:\n",
    "            articles_file.write(item[\"article\"].decode(\"utf-8\") + \"\\n\")\n",
    "            articles_file.flush()\n",
    "            highlights_file.write(item[\"highlights\"].decode(\"utf-8\").replace(\"\\n\", \" \") + \"\\n\")\n",
    "            highlights_file.flush()\n",
    "\n",
    "    write_data(train_ds_iter, \"train\")\n",
    "    write_data(test_ds_iter, \"test\")\n",
    "    write_data(val_ds_iter, \"val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/yannik/.cache/torch/hub/pytorch_fairseq_master\n",
      "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    }
   ],
   "source": [
    "# Load an En-De Transformer model trained on WMT'19 data:\n",
    "en2de = torch.hub.load('pytorch/fairseq', 'transformer.wmt19.en-de.single_model', tokenizer='moses', bpe='fastbpe')\n",
    "\n",
    "# Access the underlying TransformerModel\n",
    "assert isinstance(en2de.models[0], torch.nn.Module)\n",
    "\n",
    "# Translate from En-De\n",
    "de = en2de.translate('PyTorch Hub is a pre-trained model repository designed to facilitate research reproducibility.')\n",
    "assert de == 'PyTorch Hub ist ein vorgefertigtes Modell-Repository, das die Reproduzierbarkeit der Forschung erleichtern soll.'\n",
    "\n",
    "# to gpu\n",
    "en2de = en2de.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "upEvVDG1fB4t"
   },
   "outputs": [],
   "source": [
    "def read_files(name):\n",
    "    article_path = \"../../data/%s/article\" % name\n",
    "    highlights_path = \"../../data/%s/highlights\" % name\n",
    "    \n",
    "    articles = [x.rstrip() for x in open(article_path).readlines()]\n",
    "    highlights = [x.rstrip() for x in open(highlights_path).readlines()]\n",
    "    \n",
    "    assert len(articles) == len(highlights)\n",
    "    return articles, highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_in_sentences(text):\n",
    "    return split_single(text)\n",
    "\n",
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, articles):\n",
    "        self.x = articles\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        sentences = split_in_sentences(self.x[index]) \n",
    "        ret_x = []\n",
    "        for i, sent in enumerate(sentences): \n",
    "            \n",
    "            ret_x.append(sent[:1024])\n",
    "            \n",
    "        \n",
    "        return ret_x\n",
    "    \n",
    "    @staticmethod\n",
    "    def transfrom(x):\n",
    "        x = x.lower()\n",
    "        x = re.sub(\"'(.*)'\", r\"\\1\", x)\n",
    "        return x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_name = \"train\"\n",
    "articles, highlights = read_files(ds_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_ds = MyDataset(articles)\n",
    "\n",
    "highlights_ds = MyDataset(highlights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62926"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FileWriter:\n",
    "    def __init__(self, ds_name, name, path=\"../../data/\"):\n",
    "        self.path = path + ds_name + \"/\"+ name + \"_german\"\n",
    "        self.file = Path(self.path).open(\"a\")\n",
    "        \n",
    "    def write_translated(self, i, list_str):    \n",
    "        result = str(i) + \"; \"\n",
    "        for item_str in list_str:\n",
    "            result += item_str + \" \"\n",
    "        self.file.write(result.replace(\"\\n\", \" \") + \"\\n\")\n",
    "        self.file.flush()\n",
    "    \n",
    "    def get_last_index(self):\n",
    "        with open(self.path) as fileObj:\n",
    "            ret_list = list(fileObj)\n",
    "            if len(ret_list) > 0: \n",
    "                return int(ret_list[-1].split(\";\")[0])\n",
    "            else: \n",
    "                return 0\n",
    "        \n",
    "    \n",
    "file_writer = FileWriter(\"train\", \"articles\")  \n",
    "file_writer.get_last_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_writer = FileWriter(\"train\", \"highlights\")  \n",
    "file_writer.get_last_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(ds, ds_name, name, log_interval=1000):\n",
    "    len_ds = len(ds)\n",
    "\n",
    "    file_writer = FileWriter(ds_name, name)\n",
    "    first_index = file_writer.get_last_index()\n",
    "    start_time = time.time()\n",
    "    for i in range(first_index, len_ds):\n",
    "        predictions = en2de.translate(ds[i])\n",
    "        file_writer.write_translated(i, predictions)\n",
    "        elapsed = time.time() - start_time  \n",
    "        if ((i+1) % log_interval) == 0:\n",
    "            elapsed = time.time() - start_time  \n",
    "            print(\"| [{:5d}/{:5d}] | ms/ds_point {:5.2f} |\".format(i, len(articles_ds), (elapsed * 1000 / log_interval)))\n",
    "            start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "translate(articles_ds, \"train\", \"articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| [  999/287113] | ms/ds_point 463.11 |\n",
      "| [ 1999/287113] | ms/ds_point 466.38 |\n",
      "| [ 2999/287113] | ms/ds_point 458.61 |\n",
      "| [ 3999/287113] | ms/ds_point 466.97 |\n",
      "| [ 4999/287113] | ms/ds_point 456.94 |\n",
      "| [ 5999/287113] | ms/ds_point 473.57 |\n",
      "| [ 6999/287113] | ms/ds_point 479.82 |\n",
      "| [ 7999/287113] | ms/ds_point 478.12 |\n",
      "| [ 8999/287113] | ms/ds_point 482.09 |\n",
      "| [ 9999/287113] | ms/ds_point 484.19 |\n",
      "| [10999/287113] | ms/ds_point 487.08 |\n",
      "| [11999/287113] | ms/ds_point 506.66 |\n",
      "| [12999/287113] | ms/ds_point 490.21 |\n",
      "| [13999/287113] | ms/ds_point 482.32 |\n",
      "| [14999/287113] | ms/ds_point 467.15 |\n",
      "| [15999/287113] | ms/ds_point 496.89 |\n",
      "| [16999/287113] | ms/ds_point 502.42 |\n",
      "| [17999/287113] | ms/ds_point 487.37 |\n",
      "| [18999/287113] | ms/ds_point 491.96 |\n",
      "| [19999/287113] | ms/ds_point 480.26 |\n",
      "| [20999/287113] | ms/ds_point 469.65 |\n",
      "| [21999/287113] | ms/ds_point 478.49 |\n",
      "| [22999/287113] | ms/ds_point 477.43 |\n",
      "| [23999/287113] | ms/ds_point 482.69 |\n",
      "| [24999/287113] | ms/ds_point 528.90 |\n",
      "| [25999/287113] | ms/ds_point 783.42 |\n",
      "| [26999/287113] | ms/ds_point 784.57 |\n",
      "| [27999/287113] | ms/ds_point 771.52 |\n",
      "| [28999/287113] | ms/ds_point 792.06 |\n",
      "| [29999/287113] | ms/ds_point 794.51 |\n",
      "| [30999/287113] | ms/ds_point 764.62 |\n",
      "| [31999/287113] | ms/ds_point 596.66 |\n",
      "| [32999/287113] | ms/ds_point 482.74 |\n",
      "| [33999/287113] | ms/ds_point 476.02 |\n",
      "| [34999/287113] | ms/ds_point 492.21 |\n",
      "| [35999/287113] | ms/ds_point 484.19 |\n",
      "| [36999/287113] | ms/ds_point 484.76 |\n",
      "| [37999/287113] | ms/ds_point 484.27 |\n",
      "| [38999/287113] | ms/ds_point 486.08 |\n",
      "| [39999/287113] | ms/ds_point 487.16 |\n",
      "| [40999/287113] | ms/ds_point 495.80 |\n",
      "| [41999/287113] | ms/ds_point 477.82 |\n",
      "| [42999/287113] | ms/ds_point 474.28 |\n",
      "| [43999/287113] | ms/ds_point 482.27 |\n",
      "| [44999/287113] | ms/ds_point 476.13 |\n",
      "| [45999/287113] | ms/ds_point 471.19 |\n",
      "| [46999/287113] | ms/ds_point 461.69 |\n",
      "| [47999/287113] | ms/ds_point 481.99 |\n",
      "| [48999/287113] | ms/ds_point 478.24 |\n",
      "| [49999/287113] | ms/ds_point 481.96 |\n",
      "| [50999/287113] | ms/ds_point 485.28 |\n",
      "| [51999/287113] | ms/ds_point 467.98 |\n",
      "| [52999/287113] | ms/ds_point 497.23 |\n",
      "| [53999/287113] | ms/ds_point 486.32 |\n",
      "| [54999/287113] | ms/ds_point 501.98 |\n",
      "| [55999/287113] | ms/ds_point 479.92 |\n",
      "| [56999/287113] | ms/ds_point 489.41 |\n",
      "| [57999/287113] | ms/ds_point 485.25 |\n",
      "| [58999/287113] | ms/ds_point 475.00 |\n",
      "| [59999/287113] | ms/ds_point 484.14 |\n",
      "| [60999/287113] | ms/ds_point 482.92 |\n",
      "| [61999/287113] | ms/ds_point 504.81 |\n",
      "| [62999/287113] | ms/ds_point 481.65 |\n",
      "| [63999/287113] | ms/ds_point 490.60 |\n",
      "| [64999/287113] | ms/ds_point 489.81 |\n",
      "| [65999/287113] | ms/ds_point 488.02 |\n",
      "| [66999/287113] | ms/ds_point 490.95 |\n",
      "| [67999/287113] | ms/ds_point 493.37 |\n",
      "| [68999/287113] | ms/ds_point 490.78 |\n",
      "| [69999/287113] | ms/ds_point 483.46 |\n",
      "| [70999/287113] | ms/ds_point 475.08 |\n",
      "| [71999/287113] | ms/ds_point 477.23 |\n",
      "| [72999/287113] | ms/ds_point 479.61 |\n",
      "| [73999/287113] | ms/ds_point 488.83 |\n",
      "| [74999/287113] | ms/ds_point 479.95 |\n",
      "| [75999/287113] | ms/ds_point 485.87 |\n",
      "| [76999/287113] | ms/ds_point 478.18 |\n",
      "| [77999/287113] | ms/ds_point 488.37 |\n",
      "| [78999/287113] | ms/ds_point 486.94 |\n",
      "| [79999/287113] | ms/ds_point 480.36 |\n",
      "| [80999/287113] | ms/ds_point 493.49 |\n",
      "| [81999/287113] | ms/ds_point 490.70 |\n",
      "| [82999/287113] | ms/ds_point 481.86 |\n",
      "| [83999/287113] | ms/ds_point 473.13 |\n",
      "| [84999/287113] | ms/ds_point 489.27 |\n",
      "| [85999/287113] | ms/ds_point 490.98 |\n",
      "| [86999/287113] | ms/ds_point 492.49 |\n",
      "| [87999/287113] | ms/ds_point 482.20 |\n"
     ]
    }
   ],
   "source": [
    "translate(highlights_ds, \"train\", \"highliths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of pytorch_fairseq_translation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "textsummary",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
