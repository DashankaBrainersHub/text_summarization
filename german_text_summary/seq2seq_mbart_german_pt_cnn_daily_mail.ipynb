{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Text Summary with the tranlated CNN Daily Mail Dataset\n",
    "This time We will try out a Seq2Seq mBart Model which is pretrained on German data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import re\n",
    "import time\n",
    "\n",
    "from transformers import BertTokenizer, EncoderDecoderModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 6\n",
    "\n",
    "SHUFFEL_SIZE = 1024\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "learning_rate = 3e-5\n",
    "\n",
    "EPOCHS = 1\n",
    "\n",
    "log_interval = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"bert-base-german-cased\", \"bert-base-german-cased\").to(device)\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "\n",
    "\n",
    "# model = EncoderDecoderModel.from_encoder_decoder_pretrained(\"distilbert-base-german-cased\", \"distilbert-base-german-cased\").to(device)\n",
    "\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"distilbert-base-german-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLS token will work as BOS token\n",
    "tokenizer.bos_token = tokenizer.cls_token\n",
    "\n",
    "# SEP token will work as EOS token\n",
    "tokenizer.eos_token = tokenizer.sep_token\n",
    "\n",
    "# set decoding params\n",
    "model.config.decoder_start_token_id = tokenizer.bos_token_id\n",
    "model.config.eos_token_id = tokenizer.eos_token_id\n",
    "model.config.max_length = 142\n",
    "model.config.min_length = 56\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.early_stopping = True\n",
    "model.length_penalty = 2.0\n",
    "model.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate, weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_translated_ds(name):\n",
    "    article_path = \"../data/%s/articles_german\" % name\n",
    "    highlights_path = \"../data/%s/highlights_german\" % name\n",
    "\n",
    "    articles = [x.rstrip() for x in open(article_path).readlines()]\n",
    "    highlights = [x.rstrip() for x in open(highlights_path).readlines()]\n",
    "    \n",
    "    assert len(articles) == len(highlights)\n",
    "    return articles, highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = get_translated_ds(\"train\")\n",
    "test_x, test_y = get_translated_ds(\"test\")\n",
    "val_x, val_y = get_translated_ds(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, articles, highlights):\n",
    "        self.x = articles\n",
    "        self.y = highlights\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = tokenizer.encode_plus(self.transfrom(self.x[index][3:]), max_length=512, return_tensors=\"pt\", pad_to_max_length=True)\n",
    "        y = tokenizer.encode(self.transfrom(self.y[index][3:]), max_length=150, return_tensors=\"pt\", pad_to_max_length=True)\n",
    "        return x['input_ids'].view(-1), x['attention_mask'].view(-1), y.view(-1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def transfrom(x):\n",
    "        x = re.sub(\"'(.*)'\", r\"\\1\", x)\n",
    "        return x\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6, 512]), torch.Size([6, 512]), torch.Size([6, 150]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = MyDataset(train_x, train_y) \n",
    "val_ds = MyDataset(val_x, val_y)\n",
    "test_ds = MyDataset(test_x, test_y)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
    "\n",
    "x, x_mask, y = next(iter(val_loader))\n",
    "x.shape, x_mask.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_token_id = tokenizer.pad_token_id\n",
    "def step(inputs_ids, attention_mask, y):\n",
    "    y_ids = y[:, :-1].contiguous()\n",
    "    lm_labels = y[:, 1:].clone()\n",
    "    lm_labels[y[:, 1:] == pad_token_id] = -100\n",
    "    output = model(inputs_ids, attention_mask=attention_mask, decoder_input_ids=y_ids, lm_labels=lm_labels)\n",
    "#     output = model(inputs_ids, decoder_input_ids=y, lm_labels=y)\n",
    "    return output[0] # loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | [  199/47853] | ms/batch 231.27 | loss  6.75 | val loss  6.78\n",
      "| epoch   0 | [  399/47853] | ms/batch 232.28 | loss  6.30 | val loss  6.62\n",
      "| epoch   0 | [  599/47853] | ms/batch 229.37 | loss  6.59 | val loss  6.54\n",
      "| epoch   0 | [  799/47853] | ms/batch 230.47 | loss  6.31 | val loss  6.46\n",
      "| epoch   0 | [  999/47853] | ms/batch 231.63 | loss  5.96 | val loss  6.40\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5e1aab20beba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dokumente/text_summarization/venv/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m                 \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m                 \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train() \n",
    "    start_time = time.time()\n",
    "    for i, (inputs_ids, attention_mask, y) in enumerate(train_loader):\n",
    "        inputs_ids = inputs_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss = step(inputs_ids, attention_mask, y)\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "            \n",
    "        if (i + 1) % log_interval == 0:\n",
    "            with torch.no_grad():\n",
    "                x, x_mask, y = next(iter(val_loader))\n",
    "                x = x.to(device)\n",
    "                x_mask = x_mask.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                v_loss = step(x, x_mask, y)\n",
    "                v_loss = v_loss.item()\n",
    "                \n",
    "                \n",
    "                elapsed = time.time() - start_time\n",
    "                print('| epoch {:3d} | [{:5d}/{:5d}] | '\n",
    "                  'ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | val loss {:5.2f}'.format(\n",
    "                    epoch, i, len(train_loader),\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    loss.item(), v_loss))\n",
    "                start_time = time.time()\n",
    "                val_loss.append(v_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "from rouge_score import scoring\n",
    "\n",
    "class RougeScore:\n",
    "    '''\n",
    "    mostly from https://github.com/google-research/text-to-text-transfer-transformer/blob/master/t5/evaluation/metrics.py \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, score_keys=None)-> None:\n",
    "        super().__init__()\n",
    "        if score_keys is None:  \n",
    "            self.score_keys = [\"rouge1\", \"rouge2\", \"rougeLsum\"]\n",
    "        \n",
    "        self.scorer = rouge_scorer.RougeScorer(self.score_keys)\n",
    "        self.aggregator = scoring.BootstrapAggregator()\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def prepare_summary(summary):\n",
    "            # Make sure the summary is not bytes-type\n",
    "            # Add newlines between sentences so that rougeLsum is computed correctly.\n",
    "            summary = summary.replace(\" . \", \" .\\n\")\n",
    "            return summary\n",
    "    \n",
    "    def __call__(self, target, prediction):\n",
    "        \"\"\"Computes rouge score.''\n",
    "        Args:\n",
    "        targets: string\n",
    "        predictions: string\n",
    "        \"\"\"\n",
    "\n",
    "        target = self.prepare_summary(target)\n",
    "        prediction = self.prepare_summary(prediction)\n",
    "        \n",
    "        self.aggregator.add_scores(self.scorer.score(target=target, prediction=prediction))\n",
    "\n",
    "        return \n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.rouge_list = []\n",
    "\n",
    "    def result(self):\n",
    "        result = self.aggregator.aggregate()\n",
    "        \n",
    "        for key in self.score_keys:\n",
    "            score_text = \"%s = %.2f, 95%% confidence [%.2f, %.2f]\"%(\n",
    "                key,\n",
    "                result[key].mid.fmeasure*100,\n",
    "                result[key].low.fmeasure*100,\n",
    "                result[key].high.fmeasure*100\n",
    "            )\n",
    "            print(score_text)\n",
    "        \n",
    "        return {key: result[key].mid.fmeasure*100 for key in self.score_keys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n",
      "Setting `pad_token_id` to 4 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rouge1 = 10.95, 95% confidence [10.06, 11.90]\n",
      "rouge2 = 0.09, 95% confidence [0.00, 0.21]\n",
      "rougeLsum = 9.97, 95% confidence [9.10, 10.82]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rouge1': 10.950125198510523,\n",
       " 'rouge2': 0.0855510805759562,\n",
       " 'rougeLsum': 9.970408419899043}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge_score = RougeScore()\n",
    "predictions = []\n",
    "for i, (input_ids, attention_mask, y) in enumerate(test_loader):\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)\n",
    "    y = y.to(device)\n",
    "        \n",
    "    summaries = model.generate(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    pred = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summaries]\n",
    "    real = [tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in y]\n",
    "    for pred_sent, real_sent in zip(pred, real):\n",
    "        rouge_score(pred_sent, real_sent)\n",
    "        predictions.append(str(\"pred sentence: \" + pred_sent + \"\\n\\n real sentence: \" + real_sent))\n",
    "    if i > 10:\n",
    "        break\n",
    "    \n",
    "rouge_score.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "pred sentence: ;sss ,ss - , , , der der - - - , der - von - - \" \" \" , \" \"e \" \" . \" \" - \" , der \" \"y \" \" in \" \" ist \" \" mit \" \"s \" \" wird \" \" der \" - - . \" . ist \"ey \" , ein \" \"er \" \"\n",
      "\n",
      " real sentence: Experten bezweifeln , ob überfüllte Flugzeuge Passagiere gefährden . Die US - Verbraucherberatungsgruppe sagt , dass Mindestabstände vorgeschrieben werden müssen . Sicherheitstests in Flugzeugen mit mehr Beinfreiheit als von Fluggesellschaften angeboten , werden durchgeführt .\n",
      "------\n",
      "------\n",
      "pred sentence: ;sss - - - , , , der der - -ige - - von , , und , , \" \" \" , \" , , ein \" \"r \" \" . \" \"e \" \" der \" \" - \" \" in \" \"y \" \" wird \" \" für \" \"al \" \"\n",
      "\n",
      " real sentence: Betrunkener Teenager kletterte in Löwengehege eines Zoos in Westindien : Rahul Kumar , 17 , lief auf Tiere zu und schrie : \" Heute töte ich einen Löwen ! \" Glücklicherweise stürzte er in einen Wassergraben , bevor er die Löwen erreichte und wurde gerettet .\n",
      "------\n",
      "------\n",
      "pred sentence: ; - - - , , , der - -ige - - von - - \" \" \" , \" \" - \" , , \" , er \" \" . \" \" ist \" \"er \" \" der \" \"e \" \" sagt \" \"y \" \"s \" \"\n",
      "\n",
      " real sentence: Nottingham Forest steht kurz vor der Vertragsverlängerung von Dougie Freedman , der im Februar die Nachfolge des ehemaligen Managers Stuart Pearce angetreten hatte und den Club seitdem auf den neunten Tabellenplatz geführt hat .\n",
      "------\n",
      "------\n",
      "pred sentence: ;sss , , , der der - - - von - - , , in , , am . , , im von York in York , , wurde in Nacht in Nacht Nacht Nacht einem in Haus , , er , , ein , , \" \" \" , \"e \" \" . \" \" ich ich \" \" sagte \" \"\n",
      "\n",
      " real sentence: Fiorentina - Torhüter Neto wurde mit Liverpool und Arsenal in Verbindung gebracht . Neto kam 2011 vom brasilianischen Erstligisten Atletico Paranaense zu Fiorentina und wird laut seinem Agenten auch von PSG und spanischen Clubs gesucht .\n",
      "------\n",
      "------\n",
      "pred sentence: ;e , , , in , , sie , , die , , er , ,e , sie und , , der , , ihr , , \" \" \" , , sich sich , sie \" \" zu \" \" . , , eine , , Frau , , ein ,r , , von sie , sie sie , \" , \" sie \" , sie ihr \" \"\n",
      "\n",
      " real sentence: Das Interview mit dem Reality - TV - Star , 69 , wird am Freitag , den 24 . April ausgestrahlt , inmitten anhaltender Spekulationen über seinen Wechsel zu einer Frau und nach seiner Verwicklung in einen tödlichen Autounfall im Februar . Das Interview wird auch einer von Diane Sawyers ersten Fernsehauftritten nach dem plötzlichen Tod ihres Mannes im vergangenen Jahr sein .\n",
      "------\n",
      "------\n",
      "pred sentence: ;EUEU Die derEUEUEU Der -EUEU Präsident , , die der - - - , der - , , der der -EU Präsident \" , , , den der - der - undEUEU \"EUEU AußenministerEUEU Ein - - der derEU dieEUEU , die die derEU , ,EUEU\n",
      "\n",
      " real sentence: Riesenschwein fiel in den Swimmingpool seines Hauses in Ringwood , Hampshire . Es bedurfte der Anstrengungen eines Teams von Feuerwehrleuten , um es aus dem Wasser zu ziehen . Auch ein eigensinniges Pferd musste aus einem Swimmingpool in Sussex gerettet werden .\n",
      "------\n",
      "------\n",
      "pred sentence: ;sss - - - , , der - -ische - - vonyyy , , , am . .yyss , , von , , er , , und , , die , , sich der - \" \" \" - \" . \" \"e \" \" , \" \" der \" \"dy \" \" .y \" \" in \" \"y \"\n",
      "\n",
      " real sentence: In den letzten drei Monaten des Jahres 2014 verbrachte der durchschnittliche Hörer zehn Stunden pro Woche mit Tuning . Das waren 14 % weniger als zehn Jahre zuvor , als die Menschen 11 , 6 Stunden lang einschalteten . Der BBC Trust hat Firmen den Weg geebnet , sich in einem Product - Placement - Experiment in Lifestyleprogramme auf dem World News - Kanal einzukaufen . Zum Beispiel könnten Verlage dafür bezahlen , dass ihre Bücher auf Talking Books rezensiert werden . Der BBC Trust wird das Programm in einem Jahr überprüfen .\n",
      "------\n",
      "------\n",
      "pred sentence: ;sss - - - , , , der der - -ige - - von - - \" \" \" , \" \" . \" \" die \" \" - \" , der \" \"e \" \" wird \" \" in \" \" ist \" \" der \" - - . \" . ist \" -ig \" \"\n",
      "\n",
      " real sentence: Die Show werde mit einem einstündigen Special zurückkehren , gefolgt von einem Spin - off , sagte Star John Stamos , der die Show am Montagabend auf \" Jimmy Kimmel Live \" ankündigte .\n",
      "------\n",
      "------\n",
      "pred sentence: ;yyy , , , von , , in , , er , , am . , , sie , , sich , sie der , , \" \" \" , , die \" \"e \" \" . , sie \" \" in \" \" - \" \" und \" \"y \" \"\n",
      "\n",
      " real sentence: Reanne Evans traf in der WM - Qualifikation auf Ken Doherty . Doherty gewann 1997 die Weltmeisterschaft . Evans verlor den ersten Frame 71 - 15 gegen Doherty . Doch der gebürtige Dudley kämpfte sich zurück und führte 4 - 3 . Ken Doherty gelang es jedoch , einen packenden Wettkampf mit 10 - 8 zu beenden .\n",
      "------\n",
      "------\n",
      "pred sentence: ;yyy , , , von , , in , , er , , seine , ,e , , sie , , die , , sich , , zu , sie zu , , ihr zu , er zu , sich zu , und , , \" \" \" , , ich \" \"e \" \" Ich , ich , , es \" \" .y , sie sie , sie die , sie \" , sie ihr \" \"\n",
      "\n",
      " real sentence: Wegen sexuellen Missbrauchs von Kindern muss die Bande insgesamt 31 Jahre ins Gefängnis . Die Taten ereigneten sich in Autos , Wäldern oder in den Wohnungen der Angeklagten in Banbury . Opfer wurden zu Partys gelockt , die über soziale Medien organisiert wurden , und dann missbraucht . Mädchen im Alter zwischen 13 und 16 Jahren wurden von der Bande zwischen 2009 und 2014 ausgebeutet .\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "for pred in predictions[:10]:\n",
    "    print(\"------\")\n",
    "    print(pred)\n",
    "    print(\"------\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path = \"../data/bert_result_german.txt\"\n",
    "for pred in predictions:\n",
    "    with open(result_path, \"a\") as file:\n",
    "        file.write(pred + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "textsummary",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
