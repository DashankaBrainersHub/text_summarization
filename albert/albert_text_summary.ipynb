{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from my_sentence_piecer import MySentencePiecer\n",
    "from albert_pre import AlbertPre\n",
    "from tf_to_csv import TfToCsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 'GeForce RTX 2080 Ti')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device(), torch.cuda.get_device_name(device=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "MAX_SENT_N = 30\n",
    "\n",
    "MAX_WORD_N = 150\n",
    "\n",
    "MAX_WORD_SENT_N = 300\n",
    "\n",
    "BATCHSIZE = 20\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Sentence Piecer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentence_piecer = MySentencePiecer(vocab_size=10000, force_update=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "['<unk>', '<s>', '</s>', '▁the', 's', ',', '.', '▁to', '▁a', '▁in', '▁of', '▁and', '▁.', \"'\", '-', '▁was', '▁for', '▁on', '▁is', '▁he']\n",
      "[1459, 118, 5, 46, 13, 74, 1111, 6, 57, 18, 220, 1100, 4, 6, 2]\n",
      " hallo, i'm leaving. this is another sentences.</s>\n"
     ]
    }
   ],
   "source": [
    "print(sentence_piecer.vocab_size)\n",
    "print(sentence_piecer.vocab_list[:20])\n",
    "test = \"hallo, i'm leaving. this is another sentences.\"\n",
    "tokens = sentence_piecer.get_ids_from_vocab(test)\n",
    "print(tokens)\n",
    "print(sentence_piecer.get_real_text_from_ids(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "eos_token = sentence_piecer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "albert_pre = AlbertPre()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, article, n_articles, highlights, n_highlights):\n",
    "        self.x = self.to_tensor_list(article, dtype=torch.float)\n",
    "        self.x_n = torch.tensor(n_articles, dtype=torch.long)\n",
    "\n",
    "        self.y_n = torch.tensor(n_highlights, dtype=torch.long)\n",
    "        self.y = self.to_tensor_list(highlights, dtype=torch.long, pad=MAX_WORD_N)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        x_n = self.x_n[index]\n",
    "        y_n = self.y_n[index]\n",
    "        y = self.y[index]\n",
    "\n",
    "        return x, x_n, y, y_n\n",
    "\n",
    "    @staticmethod\n",
    "    def to_tensor_list(x, dtype, pad=None):\n",
    "\n",
    "        if pad is None:\n",
    "            tensor_list = [torch.tensor(x_i, dtype=dtype) for x_i in x]\n",
    "        else:\n",
    "            tensor_list = [torch.cat((torch.tensor(x_i[:MAX_WORD_N], dtype=dtype), \\\n",
    "                                      torch.zeros(pad - x_i[:MAX_WORD_N].shape[0], dtype=dtype))) for x_i in x]\n",
    "\n",
    "        return tensor_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def load_torch_dataset(name):\n",
    "    x, x_n, y, y_n = albert_pre.load_np_files(name)\n",
    "    return MyDataset(x, x_n, y, y_n)\n",
    "\n",
    "test_ds = load_torch_dataset(\"test\")\n",
    "train_ds = load_torch_dataset(\"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCHSIZE = 20\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, batch_size=BATCHSIZE)\n",
    "test_loader = torch.utils.data.DataLoader(test_ds, batch_size=BATCHSIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# My Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model, dropout=0.1, max_len=10000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class ContextDecoder(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, out_dim=150, dropout=0.1):\n",
    "        super().__init__()\n",
    "        transfrom_decode_layer = nn.TransformerDecoderLayer(d_model, nhead, dim_feedforward,\\\n",
    "                                                            dropout=dropout, activation='relu')\n",
    "\n",
    "        self.transformer_decoder = nn.TransformerDecoder(transfrom_decode_layer, num_layers=1)\n",
    "        self.out_put_layer = nn.Linear(3072, out_dim*200)\n",
    "\n",
    "\n",
    "    def forward(self, context, c_n_max, mask=None):\n",
    "        # dims\n",
    "        bs = context.shape[0]\n",
    "        dim_context = context.shape[2]\n",
    "        \n",
    "        context_memory = torch.zeros(context[:,0,:].shape).to(device).reshape(bs,1,dim_context)\n",
    "        \n",
    "        n = torch.min(torch.max(c_n_max), torch.LongTensor([30]).to(device))\n",
    "        for i in range(n):\n",
    "            context_memory = self.transformer_decoder(context[:,i,:].reshape(bs,1,dim_context), context_memory)\n",
    "\n",
    "        # reshape\n",
    "        context_memory = context_memory.reshape(bs, dim_context)\n",
    "        out = self.out_put_layer(context_memory).reshape(150,-1,200)\n",
    "        return out\n",
    "\n",
    "\n",
    "\n",
    "class TransformerModel(nn.Module):\n",
    "\n",
    "    def __init__(self, n_vocab, emsize, nhead, nhid, nlayers, max_sent=30, c_d_model=3072, dropout=0.2, eos_token=2):\n",
    "        \"\"\"\n",
    "        @param n_vocab: vocab_size\n",
    "        @param emsize: embedding size\n",
    "        @param nhead: the number of heads in the multiheadattention models\n",
    "        @param nhid: the dimension of the feedforward network model in nn.TransformerEncoder\n",
    "        @param nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "        @param dropout: the dropout value\n",
    "        \"\"\"\n",
    "        super(TransformerModel, self).__init__()\n",
    "\n",
    "        from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
    "        self.model_type = 'Transformer'\n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(emsize, dropout)\n",
    "\n",
    "        encoder_layers = TransformerEncoderLayer(emsize, nhead, nhid, dropout)\n",
    "\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
    "        self.encoder = nn.Embedding(n_vocab, emsize)\n",
    "        self.emsize = emsize\n",
    "        self.decoder = nn.Linear(emsize, n_vocab)\n",
    "        self.eos_token = eos_token\n",
    "        self.context_decoder = ContextDecoder(c_d_model, nhead, nhid, dropout=dropout)\n",
    "        self.init_weights()\n",
    "\n",
    "    @staticmethod\n",
    "    def _generate_square_subsequent_mask(sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "\n",
    "    def predict_one(self, context, c_n):\n",
    "        context_sum = self.context_decoder(context, c_n)\n",
    "        in_src = []\n",
    "\n",
    "        for i in range(MAX_WORD_N):\n",
    "            if i == 0:\n",
    "                in_tokens = torch.ones((MAX_WORD_N, 1), dtype=torch.long).to(device)\n",
    "            else:\n",
    "                zeros = torch.ones(((MAX_WORD_N-i), 1), dtype=torch.long).to(device)\n",
    "                tokens = torch.LongTensor(in_src).view(-1,1).to(device)\n",
    "                in_tokens = torch.cat((tokens, zeros), dim=0)\n",
    "            src = self.encoder(in_tokens) * math.sqrt(self.emsize)\n",
    "            src = self.pos_encoder(src)\n",
    "           \n",
    "            output = self.transformer_encoder(src, self.src_mask)\n",
    "            output += context_sum\n",
    "            output = self.decoder(output)\n",
    "            \n",
    "            out_token = output.argmax(2)\n",
    "            out_token = out_token[i].item()\n",
    "            in_src.append(out_token)\n",
    "            if out_token == self.eos_token:\n",
    "                break\n",
    "            \n",
    "\n",
    "        return in_src\n",
    "\n",
    "\n",
    "    def forward(self, context, c_n, src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.encoder(src) * math.sqrt(self.emsize)\n",
    "        src = self.pos_encoder(src)\n",
    "           \n",
    "        output = self.transformer_encoder(src, self.src_mask)\n",
    "        context_sum = self.context_decoder(context, c_n)\n",
    "        \n",
    "        output += context_sum\n",
    "        output = self.decoder(output)\n",
    "#         print(\"output\", output.shape)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_vocab = sentence_piecer.vocab_size\n",
    "model = TransformerModel(n_vocab=n_vocab, emsize=200, nhead=8, nhid=400,\\\n",
    "                         nlayers=3, max_sent=30, c_d_model=3072, dropout=0.2, eos_token=eos_token).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 5.0 # learning rate\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_sent = iter(test_loader)\n",
    "x_test, xn_test, y_test, n_test =  next(test_sent)\n",
    "\n",
    "x_test = x_test[0,:,:].view(1,30,3072).to(device)\n",
    "xn_test = xn_test[0].to(device)\n",
    "\n",
    "n_test = n_test[0].to(device)\n",
    "y_test = y_test[0,:].view(1,150).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 30, 3072]), tensor(43, device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape, n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "real_sentence = sentence_piecer.get_real_text_from_ids(y_test.view(-1)[:n_test.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " experts question if packed out planes are putting passengers at risk . u.s consumer advisory group says minimum space must be stipulated . safety tests conducted on planes with more leg room than airlines offer .</s>\n"
     ]
    }
   ],
   "source": [
    "def evaluate(eval_model, test_loader, predict=False):\n",
    "    eval_model.eval()\n",
    "    test_loss = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (x, x_n, y, y_n) in enumerate(test_loader):\n",
    "            x = x.to(device)\n",
    "            x_n = x_n.to(device)\n",
    "            y = y.permute(1,0).to(device)\n",
    "            y_n = y_n.to(device)\n",
    "            \n",
    "            output = eval_model(x, x_n, y)\n",
    "            \n",
    "            loss = criterion(output.view(MAX_WORD_N, n_vocab, -1), y)\n",
    "            test_loss.append(loss.item())\n",
    "            if i > 5:\n",
    "                break\n",
    "        if predict:\n",
    "            sent_ids = eval_model.predict_one(x_test, xn_test)\n",
    "            pred_sentence = sentence_piecer.get_real_text_from_ids(sent_ids)\n",
    "            print(\"Pred Sent: \", pred_sentence)\n",
    "\n",
    "    test_loss = np.array(test_loss)\n",
    "    return np.mean(test_loss)\n",
    "print(real_sentence)\n",
    "# evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 | [  200/  669] | lr 5.00 | ms/batch 246.17 | loss  6.71 | val loss  6.61 | ppl   822.44\n",
      "| epoch   0 | [  400/  669] | lr 5.00 | ms/batch 243.98 | loss  5.70 | val loss  5.05 | ppl   298.30\n",
      "Pred Sent:   of . . . . . . . . . of . . . . . . . . . of . . . . . . . . . of . . . . . . . . . of . . . . . . . . . of . . . . . . . . . of . .-------s---------s---------s---------s---------s---------s---------s---------s---------\n",
      "| epoch   0 | [  600/  669] | lr 5.00 | ms/batch 243.82 | loss  5.47 | val loss  4.73 | ppl   237.34\n",
      "| epoch   1 | [  200/  669] | lr 5.00 | ms/batch 245.93 | loss  5.15 | val loss  5.28 | ppl   173.10\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "log_interval = 200\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "    for i, (x, x_n, y, y_n) in enumerate(train_loader):\n",
    "        x = x.to(device)\n",
    "        x_n = x_n.to(device)\n",
    "        y = y.permute(1,0).to(device)\n",
    "        y_n = y_n.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x, x_n, y)\n",
    "#         print(\"out\", n_out.shape, n.shape)\n",
    "            \n",
    "        loss = criterion(output.view(MAX_WORD_N, n_vocab, -1), y)\n",
    "            \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if i % log_interval == 0 and i > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            predict =  (i % 600) == 0 \n",
    "            test_loss = evaluate(model, test_loader, predict)\n",
    "            print('| epoch {:3d} | [{:5d}/{:5d}] | '\n",
    "                  'lr {:02.2f} | ms/batch {:5.2f} | '\n",
    "                  'loss {:5.2f} | val loss {:5.2f} | ppl {:8.2f}'.format(\n",
    "                    epoch, i, len(train_loader),scheduler.get_last_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, test_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
